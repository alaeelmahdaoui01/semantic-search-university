[
  {
    "text": "Algorithmic Foundations : Graph Algorithms Omar Saadi omar.saadi@um6p.ma UM6P - College of Computing 1st year of the engineering degree of UM6P-CS Academic year 2024-2025 Omar Saadi (College of Computing) Algorithmic Foundations 3 Computer Science School 1 / 28",
    "source": "Chapter1_AlgoFoundations_GA.pdf",
    "page": 1
  },
  {
    "text": "Why Graphs ? Graphs have applications in many areas, including : Social networks, air networks, road networks, energy networks (electricity, gas, water,...) Mathematics : graphs are useful is many areas of mathematics (geometry, dynamic systems, operations research,...) Computer science : links between web pages, networks of communication, data organization, map networks, ... Statistical physics (interactions between parts of a system), study of molecules, ... Some of the objectives of the course : Understand the structure of graphs Learn the techniques used to analyze problems in graph theory Learn algorithms on trees and graphs Omar Saadi (College of Computing) Algorithmic Foundations 3 Computer Science School 2 / 28",
    "source": "Chapter1_AlgoFoundations_GA.pdf",
    "page": 2
  },
  {
    "text": "Chapter 1 : Fundamental concepts about graphs 1 Definition of a graph 2 Graphs as models 3 Matrix representation and isomorphism 4 Decomposition and Special graphs Omar Saadi (College of Computing) Algorithmic Foundations 3 Computer Science School 3 / 28",
    "source": "Chapter1_AlgoFoundations_GA.pdf",
    "page": 3
  },
  {
    "text": "Definition of a graph Outline 1 Definition of a graph 2 Graphs as models 3 Matrix representation and isomorphism 4 Decomposition and Special graphs Omar Saadi (College of Computing) Algorithmic Foundations 3 Computer Science School 4 / 28",
    "source": "Chapter1_AlgoFoundations_GA.pdf",
    "page": 4
  },
  {
    "text": "Definition of a graph The K¨ onigsberg Bridge Problem The city of K¨ onigsberg was located on the Pregel river in Prussia which divides it into four regions. These regions are connected together using seven bridges, as shown in the following drawing : Citizens wondered if they could take a walk in the city while crossing each bridge exactly once. The resolution of this problem was given by Leonhard Euler in 1736. Omar Saadi (College of Computing) Algorithmic Foundations 3 Computer Science School 5 / 28",
    "source": "Chapter1_AlgoFoundations_GA.pdf",
    "page": 5
  },
  {
    "text": "Definition of a graph The K¨ onigsberg Bridge Problem To simplify this problem, we reduce the drawing to the following diagram : a b c d e1 e2 e3 e4 e5 e6 e7 The four regions are represented by vertices and the seven bridges by edges. Answer : Such walk is not possible. Proof : Omar Saadi (College of Computing) Algorithmic Foundations 3 Computer Science School 6 / 28",
    "source": "Chapter1_AlgoFoundations_GA.pdf",
    "page": 6
  },
  {
    "text": "Definition of a graph Definition A graph G is a triple consisting of a vertex setV (G), an edge setE(G), and a relation that associates with each edge two vertices (not necessarily distinct) called its endpoints. Example In the graph showed above, the vertex set is {a, b, c, d}, the edge set is {e1, e2, e3, e4, e5, e6, e7}, and the assignment of endpoints to edges can be read from the diagram. Definition A loop is an edge whose endpoints are equal. Multiple edgesare edges having the same pair of endpoints. a a b Omar Saadi (College of Computing) Algorithmic Foundations 3 Computer Science School 7 / 28",
    "source": "Chapter1_AlgoFoundations_GA.pdf",
    "page": 7
  },
  {
    "text": "Definition of a graph Definition A simple graphis a graph without loops and multiple edges. A graph is loopless means that multiple edges are allowed but loops are not. Example The graph of the K¨ onigsberg bridge problem is loopless but it is not simple. Remark We specify a simple graph G by its vertex set V (G) and edge set E(G). The edge set is treated as a set of unordered pairs of vertices. We write e = uv (or e = vu) for an edge e with endpoints u and v. Definition We say that the vertices u and v are adjacent (or neighbors) if they are the endpoints of the same edge. Omar Saadi (College of Computing) Algorithmic Foundations 3 Computer Science School 8 / 28",
    "source": "Chapter1_AlgoFoundations_GA.pdf",
    "page": 8
  },
  {
    "text": "Definition of a graph Example The two following drawings show the same simple graph. The vertex set is {a, b, c, d, e} and the edge set is {ab, ac, ad, bc, bd, cd, de } : a bc d e a b c d e Remark The terms ”vertex” and ”edge” arise from solid geometry. For example the following 3-d cube has vertices linked by edges. Omar Saadi (College of Computing) Algorithmic Foundations 3 Computer Science School 9 / 28",
    "source": "Chapter1_AlgoFoundations_GA.pdf",
    "page": 9
  },
  {
    "text": "Graphs as models Outline 1 Definition of a graph 2 Graphs as models 3 Matrix representation and isomorphism 4 Decomposition and Special graphs Omar Saadi (College of Computing) Algorithmic Foundations 3 Computer Science School 10 / 28",
    "source": "Chapter1_AlgoFoundations_GA.pdf",
    "page": 10
  },
  {
    "text": "Graphs as models Acquaintance relations and subgraphs Question Does every set of six people contain three mutual acquaintances or three mutual strangers ? We can model this problem using a simple graph with a vertex for each person and an edge for each acquainted pair. Note that the “nonacquaintance” relation yields another graph with the “complementary” set of edges. Definition The complement ¯G of a simple graph G is the simple graph with vertex set V (G) defined by uv ∈ E( ¯G) if and only if uv ̸∈ E(G). A clique in a graph is a set of pairwise adjacent vertices. An independent set (or stable set) in a graph is a set of pairwise nonadjacent vertices. Omar Saadi (College of Computing) Algorithmic Foundations 3 Computer Science School 11 / 28",
    "source": "Chapter1_AlgoFoundations_GA.pdf",
    "page": 11
  },
  {
    "text": "Graphs as models In the graph G, {u, x, y} is a clique of size 3 and {u, w} is an independent set of size 2, and these are the largest such sets. Remark In the complement graph ¯G, cliques become independent sets, and independent sets become cliques. Reformulation of the above question :Is it true that every 6-vertex graph has a clique of size 3 or an independent set of size 3 ? Answer :(As exercice) Notice that by deleting the edge ux from the above graph G, we get a 5-vertex graph having no clique or independent set of size 3. So the answer is no for 5-vertex graphs. Omar Saadi (College of Computing) Algorithmic Foundations 3 Computer Science School 12 / 28",
    "source": "Chapter1_AlgoFoundations_GA.pdf",
    "page": 12
  },
  {
    "text": "Graphs as models Job assignments and bipartite graphs Question We have m jobs, and n people, but not all people are qualified for all jobs. Can we fill the jobs with qualified people ? We model this using a simple graph G with vertices for the jobs and people ; job j is adjacent to person p if p can do j. So the question is to find m pairwise disjoint edges in G. Definition A graph G is bipartite if V (G) is the union of two disjoint independent sets called partite setsof G. Omar Saadi (College of Computing) Algorithmic Foundations 3 Computer Science School 13 / 28",
    "source": "Chapter1_AlgoFoundations_GA.pdf",
    "page": 13
  },
  {
    "text": "Graphs as models Scheduling and graph coloring Question Suppose we must schedule Parliament committee meetings into designated weekly time periods. We cannot assign two committees to the same time if they have a common member. How many different time periods do we need ? Modeling : We create a vertex for each committee, with two vertices adjacent when the two committees have a common member. We must assign labels (time periods) to the vertices such that adjacent vertices receive different labels. Example : We can use one color (label) for each of the three independent sets. The members of a clique must receive distinct labels ⇒ the minimum number of colors (time periods) is three. Omar Saadi (College of Computing) Algorithmic Foundations 3 Computer Science School 14 / 28",
    "source": "Chapter1_AlgoFoundations_GA.pdf",
    "page": 14
  },
  {
    "text": "Graphs as models Scheduling and graph coloring Question Suppose we must schedule Parliament committee meetings into designated weekly time periods. We cannot assign two committees to the same time if they have a common member. How many different time periods do we need ? Modeling : We create a vertex for each committee, with two vertices adjacent when the two committees have a common member. We must assign labels (time periods) to the vertices such that adjacent vertices receive different labels. Example : We can use one color (label) for each of the three independent sets. The members of a clique must receive distinct labels ⇒ the minimum number of colors (time periods) is three. Example : We can use one color (label) for each of the three independent sets. The members of a clique must receive distinct labels ⇒ the minimum number of colors (time periods) is three. Omar Saadi (College of Computing) Algorithmic Foundations 3 Computer Science School 14 / 28",
    "source": "Chapter1_AlgoFoundations_GA.pdf",
    "page": 15
  },
  {
    "text": "Graphs as models Scheduling and graph coloring Question Suppose we must schedule Parliament committee meetings into designated weekly time periods. We cannot assign two committees to the same time if they have a common member. How many different time periods do we need ? Modeling : We create a vertex for each committee, with two vertices adjacent when the two committees have a common member. We must assign labels (time periods) to the vertices such that adjacent vertices receive different labels. Example : We can use one color (label) for each of the three independent sets. The members of a clique must receive distinct labels ⇒ the minimum number of colors (time periods) is three. Omar Saadi (College of Computing) Algorithmic Foundations 3 Computer Science School 14 / 28",
    "source": "Chapter1_AlgoFoundations_GA.pdf",
    "page": 16
  },
  {
    "text": "Graphs as models Definition A coloring of a graph is an assignment of a color to each vertex such that adjacent vertices receive different colors. The chromatic number of a graph G, written χ(G), is the minimum number of colors needed to color G. A graph G is k-partite if V (G) can be expressed as the union of k (possibly empty) independent sets. So the above question is asking about the chromatic number of the graph and the corresponding coloring. Remark The k-partite notion generalizes the idea of bipartite graphs, which are 2-partite. A graph is k-partite if and only if its chromatic number is at most k. Omar Saadi (College of Computing) Algorithmic Foundations 3 Computer Science School 15 / 28",
    "source": "Chapter1_AlgoFoundations_GA.pdf",
    "page": 17
  },
  {
    "text": "Graphs as models Routes in road networks Modeling : We can model a road network using a graph where : Vertices are intersections, Edges are road segments between intersections, We can assign edge weights to measure distance or travel time. Question How can we find the shortest route from a point x to a point y ? Omar Saadi (College of Computing) Algorithmic Foundations 3 Computer Science School 16 / 28",
    "source": "Chapter1_AlgoFoundations_GA.pdf",
    "page": 18
  },
  {
    "text": "Graphs as models Definition A path is a simple graph whose vertices can be ordered so that two vertices are adjacent if and only if they are consecutive in the list. A cycle is a graph with an equal number of vertices and edges whose vertices can be placed around a circle so that two vertices are adjacent if and only if they appear consecutively along the circle. Example : a path a cycle Definition A subgraph of a graph G is a graph H such that V (H) ⊂ V (G) and E(H) ⊂ E(G) and the assignment of endpoints to edges in H is the same as in G. We write H ⊂ G and say that “ G contains H”. A graph G is connected if each pair of vertices in G is connected by a path ; otherwise, G is disconnected. Omar Saadi (College of Computing) Algorithmic Foundations 3 Computer Science School 17 / 28",
    "source": "Chapter1_AlgoFoundations_GA.pdf",
    "page": 19
  },
  {
    "text": "Matrix representation and isomorphism Outline 1 Definition of a graph 2 Graphs as models 3 Matrix representation and isomorphism 4 Decomposition and Special graphs Omar Saadi (College of Computing) Algorithmic Foundations 3 Computer Science School 18 / 28",
    "source": "Chapter1_AlgoFoundations_GA.pdf",
    "page": 20
  },
  {
    "text": "Matrix representation and isomorphism Matrix representation Definition Let G be a loopless graph with vertex set V (G) = {v1, . . . ,vn} and edge set E(G) = {e1, ··· , em}. The adjacency matrixof G, written A(G), is the n-by-n matrix in which entry aij is the number of edges in G with endpoints {vi , vj }. The incidence matrixM(G) is the n-by-m matrix in which entry mij is 1 if vi is an endpoint of ej and otherwise is 0. Example : Omar Saadi (College of Computing) Algorithmic Foundations 3 Computer Science School 19 / 28",
    "source": "Chapter1_AlgoFoundations_GA.pdf",
    "page": 21
  },
  {
    "text": "Matrix representation and isomorphism Definition If vertex v is an endpoint of edge e, we say that v and e are incident. The degree of vertex v (in a loopless graph) is the number of incident edges to v. We denote the degree of v by deg(v). Remark An adjacency matrix is determined by a vertex ordering. Every adjacency matrix is symmetric ( aij = aji for all i, j). An adjacency matrix of a simple graph G has entries 0 or 1, with 0s on the diagonal. The degree of v is the sum of the entries in the row for v in either A(G) or M(G). Omar Saadi (College of Computing) Algorithmic Foundations 3 Computer Science School 20 / 28",
    "source": "Chapter1_AlgoFoundations_GA.pdf",
    "page": 22
  },
  {
    "text": "Matrix representation and isomorphism Graph isomorphism Definition An isomorphism from a simple graph G to a simple graph H is a bijection f : V (G) → V (H) such that uv ∈ E(G) if and only if f (u)f (v) ∈ E(H). We say “G is-isomorphic to H”, written G ∼= H, if there is an isomorphism from G to H. Example : The following graphs G and H are isomorphic : Proposition The isomorphism relation is an equivalence relation on the set of (simple) graphs. Proof : Omar Saadi (College of Computing) Algorithmic Foundations 3 Computer Science School 21 / 28",
    "source": "Chapter1_AlgoFoundations_GA.pdf",
    "page": 23
  },
  {
    "text": "Matrix representation and isomorphism Recall An equivalence relation partitions a set into equivalence classes ; two elements satisfy the relation if and only if they lie in the same class. Definition An isomorphism classof graphs is an equivalence class of graphs under the isomorphism relation. We use the expression “unlabeled graph” to mean an isomorphism class of graphs. Omar Saadi (College of Computing) Algorithmic Foundations 3 Computer Science School 22 / 28",
    "source": "Chapter1_AlgoFoundations_GA.pdf",
    "page": 24
  },
  {
    "text": "Matrix representation and isomorphism Definition The (unlabeled) path and cycle with n vertices are denoted Pn and Cn, respectively. A complete graphis a simple graph whose vertices are pairwise adjacent ; the (unlabeled) complete graph with n vertices is denoted Kn. A complete bipartite graph(or biclique) is a simple bipartite graph such that two vertices are adjacent if and only if they are in different partite sets. When the sets have sizes r and s, the (unlabeled) biclique is denoted Kr,s . Example : Omar Saadi (College of Computing) Algorithmic Foundations 3 Computer Science School 23 / 28",
    "source": "Chapter1_AlgoFoundations_GA.pdf",
    "page": 25
  },
  {
    "text": "Decomposition and Special graphs Outline 1 Definition of a graph 2 Graphs as models 3 Matrix representation and isomorphism 4 Decomposition and Special graphs Omar Saadi (College of Computing) Algorithmic Foundations 3 Computer Science School 24 / 28",
    "source": "Chapter1_AlgoFoundations_GA.pdf",
    "page": 26
  },
  {
    "text": "Decomposition and Special graphs Decomposition of graphs Definition A decomposition of a graph is a list of subgraphs such that each edge appears in exactly one subgraph in the list. Definition and Remark A graph is self-complementary if it is isomorphic to its complement. An n-vertex graph H is self-complementary if and only if Kn has a decomposition consisting of two copies of H. Example : We can decompose K5 into two 5-cycles, and thus the 5-cycle is self-complementary (left figure). We can decompose K4 using three copies of P3 (right figure). Omar Saadi (College of Computing) Algorithmic Foundations 3 Computer Science School 25 / 28",
    "source": "Chapter1_AlgoFoundations_GA.pdf",
    "page": 27
  },
  {
    "text": "Decomposition and Special graphs Petersen graph Definition The Petersen graphis the simple graph whose vertices are the 2-element subsets of a 5-element set and whose edges are the pairs of disjoint 2-element subsets. Here, we take [5] = {1, 2, 3, 4, 5} as our 5-element set, we write the pair {a, b} as ab or ba. In the following figure, we have three ways to draw the Petersen graph : The Petersen graph consists of two disjoint 5-cycles plus edges that pair up vertices on the two 5-cycles. Omar Saadi (College of Computing) Algorithmic Foundations 3 Computer Science School 26 / 28",
    "source": "Chapter1_AlgoFoundations_GA.pdf",
    "page": 28
  },
  {
    "text": "Decomposition and Special graphs Proposition If two vertices are nonadjacent in the Petersen graph, then they have exactly one common neighbor. Proof : Definition The girth of a graph with a cycle is the length of its shortest cycle. A graph with no cycle has an infinite girth. Lemma The girth of the Petersen graph is equal to5. Proof : Omar Saadi (College of Computing) Algorithmic Foundations 3 Computer Science School 27 / 28",
    "source": "Chapter1_AlgoFoundations_GA.pdf",
    "page": 29
  },
  {
    "text": "Decomposition and Special graphs Book references Introduction to graph theory [2nded], by Douglas B. West (2001) : (See Sect 1 .1 of West’s book for more details on our chapter 1.) Algorithms on trees and graphs [2nded], by Gabriel Valiente (2021) : Omar Saadi (College of Computing) Algorithmic Foundations 3 Computer Science School 28 / 28",
    "source": "Chapter1_AlgoFoundations_GA.pdf",
    "page": 30
  },
  {
    "text": "Chapter 2 : Paths and Cycles Omar Saadi omar.saadi@um6p.ma UM6P - College of Computing 1st year of the engineering degree of UM6P-CS Academic year 2024-2025 Omar Saadi (College of Computing) Algorithmic Foundations 3 Computer Science School 1 / 27",
    "source": "Chapter2_AlgoFoundations3_GA.pdf",
    "page": 1
  },
  {
    "text": "Outline 1 Connection in graphs 2 Cycles and bipartite graphs 3 Eulerian circuits 4 Hamiltonian Cycles More details on this chapter can be found in Sect 1.2 and Sect 7.2 of D. B. West’s book. Omar Saadi (College of Computing) Algorithmic Foundations 3 Computer Science School 2 / 27",
    "source": "Chapter2_AlgoFoundations3_GA.pdf",
    "page": 2
  },
  {
    "text": "Connection in graphs Outline 1 Connection in graphs 2 Cycles and bipartite graphs 3 Eulerian circuits 4 Hamiltonian Cycles Omar Saadi (College of Computing) Algorithmic Foundations 3 Computer Science School 3 / 27",
    "source": "Chapter2_AlgoFoundations3_GA.pdf",
    "page": 3
  },
  {
    "text": "Connection in graphs Recall A path is a simple graph whose vertices can be ordered so that two vertices are adjacent if and only if they are consecutive in the list. A cycle is a graph with an equal number of vertices and edges whose vertices can be placed around a circle so that two vertices are adjacent if and only if they appear consecutively along the circle. Note that a path in a graph G is a subgraph of G that is a path (similarly for cycles). Definition A walk is a list v0, e1, v1, . . . ,ek , vk of vertices and edges such that, for 1 < i < k, the edge ei has endpoints vi−1 and vi . A trail is a walk with no repeated edge. A u, v-walk or u, v-trail has first vertex u and last vertex v ; these are its endpoints. A u, v-path is a path whose vertices of degree 1 (its endpoints) are u and v ; the others are internal vertices. The length of a walk, trail, path, or cycle is its number of edges. A walk or trail is closed if its endpoints are the same. Omar Saadi (College of Computing) Algorithmic Foundations 3 Computer Science School 4 / 27",
    "source": "Chapter2_AlgoFoundations3_GA.pdf",
    "page": 4
  },
  {
    "text": "Connection in graphs Example : In the K¨ onigsberg graph : a b c d e1 e2 e3 e4 e5 e6 e7 the list b, e4, c, e2, a, e1, b, e5, c, e4, b is a closed walk of length 5 ; it repeats edge e4 and hence is not a trail. If we delete the last edge and vertex e4, b, we obtain trail. The list a, e1, b, e4, c, e7, d is a a, d-path, and d, e6, c, e2, a, e3, d is a cycle. Remark : In a simple graph, a walk (or trail) is completely specified by its ordered list of vertices. Omar Saadi (College of Computing) Algorithmic Foundations 3 Computer Science School 5 / 27",
    "source": "Chapter2_AlgoFoundations3_GA.pdf",
    "page": 5
  },
  {
    "text": "Connection in graphs Lemma Every u, v-walk contains a u, v-path. Proof : by induction on the length l of a u, v-walk. Definition A graph G is connected if for all u, v ∈ V (G), there exists u, v-path in G (otherwise, G is disconnected). If G has a u, v-path, then u is connected to v in G. The connection relation on V (G) consists of the ordered pairs ( u, v) such that u is connected to v. Remark We recall the distinction between “adjacent” and “connected” vertices : Vertices u and v are adjacent if and only if uv ∈ E(G). Vertices u and v are connected if and only if G contains a u, v-path. Omar Saadi (College of Computing) Algorithmic Foundations 3 Computer Science School 6 / 27",
    "source": "Chapter2_AlgoFoundations3_GA.pdf",
    "page": 6
  },
  {
    "text": "Connection in graphs Remark Using the previous lemma, a way to prove that a graph is connected is by fixing a particular vertex v∗ and showing that from each vertex u ∈ V (G) there is a walk to that particular vertex v∗. Proposition The connection relation is an equivalence relation. Proof : Omar Saadi (College of Computing) Algorithmic Foundations 3 Computer Science School 7 / 27",
    "source": "Chapter2_AlgoFoundations3_GA.pdf",
    "page": 7
  },
  {
    "text": "Connection in graphs Components of a graph Definition A maximal connected subgraph of G is a subgraph that is connected and that is not contained in any other connected subgraph of G. The components of a graph G are its maximal connected subgraphs. A component (or graph) is trivial if it has no edges ; otherwise it is nontrivial. An isolated vertex is a vertex of degree 0. Remark The equivalence classes of the connection relation on V (G) are the vertex sets of the components of G. An isolated vertex forms a trivial component, consisting of one vertex and no edge. Omar Saadi (College of Computing) Algorithmic Foundations 3 Computer Science School 8 / 27",
    "source": "Chapter2_AlgoFoundations3_GA.pdf",
    "page": 8
  },
  {
    "text": "Connection in graphs Example In the following graph : we have four components. The vertex sets of these components are {p}, {q, r}, {s, t, u, v, w}, and {x, y, z}; these are the equivalence classes of the connection relation. Omar Saadi (College of Computing) Algorithmic Foundations 3 Computer Science School 9 / 27",
    "source": "Chapter2_AlgoFoundations3_GA.pdf",
    "page": 9
  },
  {
    "text": "Connection in graphs Remark Components are pairwise disjoint ; no two share a vertex. Adding an edge with endpoints in distinct components combines them into one component. Thus, adding an edge decreases the number of components by 0 or 1, Deleting an edge increases the number of components by 0 or 1. Proposition Every graph with n vertices and k edges has at least n − k components. Proof : Remark Deleting a vertex (and also all edges incident to it, to still have a graph) can increase the number of components by many. Consider the example of the K1,m, where deleting the vertex corresponding to the partite set with one vertex increases the number of components from 1 to m. Omar Saadi (College of Computing) Algorithmic Foundations 3 Computer Science School 10 / 27",
    "source": "Chapter2_AlgoFoundations3_GA.pdf",
    "page": 10
  },
  {
    "text": "Connection in graphs Cut-deges and cut-vertices Definition A cut-edge or cut-vertex of a graph is an edge or vertex whose deletion increases the number of components. We write G − e or G − M for the subgraph of G obtained by deleting an edge e or set of edges M. Similarly, we write G − v or G − S for the subgraph obtained by deleting a vertex v or set of vertices S. An induced subgraph is a subgraph obtained by deleting a set of vertices. We write G[T ] for G − ¯T , where ¯T = V (G) − T ; this is the subgraph of G induced by T . Note that when T ⊂ V (G), the induced subgraph G[T ] consists of T and all edges whose endpoints are contained in T. Omar Saadi (College of Computing) Algorithmic Foundations 3 Computer Science School 11 / 27",
    "source": "Chapter2_AlgoFoundations3_GA.pdf",
    "page": 11
  },
  {
    "text": "Connection in graphs Example : We consider the same above graph : It has cut-vertices v and y. Its cut-edges are qr, vw, xy, and yz. This graph has C4 [ (t, s, u, v) ] and P5 [ {t, s, u, v, w} ] as subgraphs but not as induced subgraphs. The graph P4 is an induced subgraph ; it is the subgraph induced by {s, t, v, w}. Omar Saadi (College of Computing) Algorithmic Foundations 3 Computer Science School 12 / 27",
    "source": "Chapter2_AlgoFoundations3_GA.pdf",
    "page": 12
  },
  {
    "text": "Connection in graphs Characterization of cut-edges in terms of cycles Theorem An edge is a cut-edge if and only if it belongs to no cycle. Proof : Omar Saadi (College of Computing) Algorithmic Foundations 3 Computer Science School 13 / 27",
    "source": "Chapter2_AlgoFoundations3_GA.pdf",
    "page": 13
  },
  {
    "text": "Cycles and bipartite graphs Outline 1 Connection in graphs 2 Cycles and bipartite graphs 3 Eulerian circuits 4 Hamiltonian Cycles Omar Saadi (College of Computing) Algorithmic Foundations 3 Computer Science School 14 / 27",
    "source": "Chapter2_AlgoFoundations3_GA.pdf",
    "page": 14
  },
  {
    "text": "Cycles and bipartite graphs Definition : A walk is odd (resp. even) if its length is odd (resp. even). A closed walk W contains a cycle C if the vertices and edges of C occur as a sublist of W , in cyclic order but not necessarily consecutive. Lemma Every closed odd walk contains an odd cycle. Proof : By induction on the length l of a closed odd walk. Omar Saadi (College of Computing) Algorithmic Foundations 3 Computer Science School 15 / 27",
    "source": "Chapter2_AlgoFoundations3_GA.pdf",
    "page": 15
  },
  {
    "text": "Cycles and bipartite graphs Theorem (K¨ onig [1936]) A graph is bipartite if and only if it has no odd cycle. Proof : Remark The theorem implies that we can prove that a graph G is not bipartite by finding an odd cycle in G ; this is much easier than examining all possible bipartitions to prove that none work. When we want to prove that G is bipartite, we define a bipartition and prove that the two sets are independent ; this is easier than examining all cycles. Omar Saadi (College of Computing) Algorithmic Foundations 3 Computer Science School 16 / 27",
    "source": "Chapter2_AlgoFoundations3_GA.pdf",
    "page": 16
  },
  {
    "text": "Eulerian circuits Outline 1 Connection in graphs 2 Cycles and bipartite graphs 3 Eulerian circuits 4 Hamiltonian Cycles Omar Saadi (College of Computing) Algorithmic Foundations 3 Computer Science School 17 / 27",
    "source": "Chapter2_AlgoFoundations3_GA.pdf",
    "page": 17
  },
  {
    "text": "Eulerian circuits Definition A graph is Eulerian if it has a closed trail containing all edges. We call a closed trail a circuit when we do not specify the first vertex but keep the list in cyclic order. An Eulerian circuit or Eulerian trail in a graph is a circuit or trail containing all the edges. An even graph is a graph with vertex degrees all even. A vertex is odd (resp. even) when its degree is odd (resp. even). A maximal path in a graph G is a path P in G that is not contained in a longer path. When a graph is finite, no path can extend forever, so maximal (non-extendible) paths exist. Omar Saadi (College of Computing) Algorithmic Foundations 3 Computer Science School 18 / 27",
    "source": "Chapter2_AlgoFoundations3_GA.pdf",
    "page": 18
  },
  {
    "text": "Eulerian circuits Lemma If every vertex of a graph G has degree at least 2, then G contains a cycle. Proof : by considering a maximal path P in G, and an endpoint of P. Theorem A graph G is Eulerian if and only if it has at most one nontrivial component and its vertices all have even degree. Proof of the theorem Necessity. Suppose that G has an Eulerian circuit C. Each passage of C through a vertex uses two incident edges, and the first edge is paired with the last at the first vertex. Hence every vertex has even degree. Also, two edges can be in the same trail only when they lie in the same component, so there is at most one nontrivial component. Omar Saadi (College of Computing) Algorithmic Foundations 3 Computer Science School 19 / 27",
    "source": "Chapter2_AlgoFoundations3_GA.pdf",
    "page": 19
  },
  {
    "text": "Eulerian circuits Proof (Cont.) Sufficiency. Assuming that the condition holds, we obtain an Eulerian circuit using induction on the number of edges, m. Basis step : m = 0. A closed trail consisting of one vertex suffices. Induction step : m > 0. With even degrees, each vertex in the nontrivial component of G has degree at least 2. By the previous Lemma, the nontrivial component has a cycle C. Let G′ be the graph obtained from G by deleting E(C). Since C has 0 or 2 edges at each vertex, each component of G′ is also an even graph. Since each component also is connected and has less than m edges, we can apply the induction hypothesis to conclude that each component of G′ has an Eulerian circuit. To combine these into an Eulerian circuit of G, we traverse C, but when a component of G′ is entered for the first time we detour along an Eulerian circuit of that component. This circuit ends at the vertex where we began the detour. When we complete the traversal of C, we have completed an Eulerian circuit of G. Illustration of the Eulerian circuit constructed : Omar Saadi (College of Computing) Algorithmic Foundations 3 Computer Science School 20 / 27",
    "source": "Chapter2_AlgoFoundations3_GA.pdf",
    "page": 20
  },
  {
    "text": "Eulerian circuits Proposition Every even graph decomposes into cycles. Proof : by induction on the number of edges. Proposition If G is a simple graph in which every vertex has degree at least k, then G contains a path of length at least k. If k ≥ 2, then G also contains a cycle of length at least k + 1. Proof : Consider an endpoint of a maximal path P. Omar Saadi (College of Computing) Algorithmic Foundations 3 Computer Science School 21 / 27",
    "source": "Chapter2_AlgoFoundations3_GA.pdf",
    "page": 21
  },
  {
    "text": "Hamiltonian Cycles Outline 1 Connection in graphs 2 Cycles and bipartite graphs 3 Eulerian circuits 4 Hamiltonian Cycles Omar Saadi (College of Computing) Algorithmic Foundations 3 Computer Science School 22 / 27",
    "source": "Chapter2_AlgoFoundations3_GA.pdf",
    "page": 22
  },
  {
    "text": "Hamiltonian Cycles Definition A graph G is Hamiltonian if it contains a spanning cycle, which is a cycle that goes through each vertex of G exactly once. Such cycle is also called a Hamiltonian cycle. Example : The notion of a Hamiltonian cycle has its origins in a game invented in 1859 by Hamilton : The game consists of a regular wooden dodecahedron (polyhedron with 12 faces and 20 vertices), as shown in the following figure The player must go through the twenty vertices exactly once following the edges of the dodecahedron and return to his starting point. Omar Saadi (College of Computing) Algorithmic Foundations 3 Computer Science School 23 / 27",
    "source": "Chapter2_AlgoFoundations3_GA.pdf",
    "page": 23
  },
  {
    "text": "Hamiltonian Cycles Some solutions in 2D : In 3D : Omar Saadi (College of Computing) Algorithmic Foundations 3 Computer Science School 24 / 27",
    "source": "Chapter2_AlgoFoundations3_GA.pdf",
    "page": 24
  },
  {
    "text": "Hamiltonian Cycles Sufficient conditions Theorem (Dirac [1952]) If G is a simple graph with n ≥ 3 vertices and ∀v ∈ V (G), deg(v) ≥ n/2, then G is Hamiltonian. Proof The proof uses contradiction and extremality. If there is a non-Hamiltonian graph satisfying the hypotheses, then adding edges cannot reduce the minimum degree. Thus we may restrict our attention to maximal non-Hamiltonian graphs with minimum degree at least n/2, where “maximal” means that adding any edge joining nonadjacent vertices creates a spanning cycle. When uv ̸∈ E(G), the maximality of G implies that G + uv contains a Hamiltonian cycle and that cycle contains the edge uv. This implies that G has a spanning path v1, ··· , vn from u = v1 to v = vn. To prove the theorem, it suffices to make a small change in this cycle to avoid using the edge uv ; this will build a spanning cycle in G. Omar Saadi (College of Computing) Algorithmic Foundations 3 Computer Science School 25 / 27",
    "source": "Chapter2_AlgoFoundations3_GA.pdf",
    "page": 25
  },
  {
    "text": "Hamiltonian Cycles Proof (Cont.) If a neighbor of u directly follows a neighbor of v on the path, such as uvi+1 ∈ E(G) and vvi ∈ E(G), then ( u, vi+1, vi+2, ··· , v, vi , vi−1, ··· , u) is a spanning cycle in G. To prove that such a cycle exists, we show that there is a common index in the sets S and T defined by S = {i : uvi+1 ∈ E(G), 1 ≤ i ≤ n − 2} and T = {i : vvi ∈ E(G), 2 ≤ i ≤ n − 1}. Summing the sizes of these sets yields |S ∪ T | + |S ∩ T | = |S| + |T | = deg(u) + deg(v) ≥ n/2 + n/2 = n. We have S ∪ T ⊂ J1, n − 1K, then |S ∪ T | ≤n − 1, hence |S ∩ T | ≥1. This means that S ∩ T ̸= ∅. So, we have established a contradiction by finding a spanning cycle in G ; hence there is no (maximal) non-Hamiltonian graph satisfying the hypotheses. Omar Saadi (College of Computing) Algorithmic Foundations 3 Computer Science School 26 / 27",
    "source": "Chapter2_AlgoFoundations3_GA.pdf",
    "page": 26
  },
  {
    "text": "Hamiltonian Cycles Remark Ore observed that the argument uses ∀v ∈ V (G), deg(v) ≥ n/2 only to show that deg( u) + deg(v) ≥ n. Therefore, we can weaken the requirement of minimum degree n/2 to require only that deg(u) + deg(v) ≥ n whenever uv ̸∈ E(G). Theorem (Ore [1960]) If G is a simple graph with n ≥ 3 vertices and deg(u) + deg(v) ≥ n for every pair of distinct non-adjacent vertices u and v of G, then G is Hamiltonian. Proof : The same as the above proof of Dirac’s theorem using the above remark. Omar Saadi (College of Computing) Algorithmic Foundations 3 Computer Science School 27 / 27",
    "source": "Chapter2_AlgoFoundations3_GA.pdf",
    "page": 27
  },
  {
    "text": "Chapter 3 : Directed graphs, and Coloring Omar Saadi omar.saadi@um6p.ma UM6P - College of Computing 1st year of the engineering degree of UM6P-CS Academic year 2023-2024 Omar Saadi (College of Computing) Algorithmic Foundations 3 Computer Science School 1 / 16",
    "source": "Chapter3_AlgoFoundations3.pdf",
    "page": 1
  },
  {
    "text": "Outline 1 Directed graphs 2 Coloring of graphs More details on this chapter can be found in Sect 1.4 and Sect. 5.1 of D. B. West’s book. Omar Saadi (College of Computing) Algorithmic Foundations 3 Computer Science School 2 / 16",
    "source": "Chapter3_AlgoFoundations3.pdf",
    "page": 2
  },
  {
    "text": "Directed graphs Outline 1 Directed graphs 2 Coloring of graphs Omar Saadi (College of Computing) Algorithmic Foundations 3 Computer Science School 3 / 16",
    "source": "Chapter3_AlgoFoundations3.pdf",
    "page": 3
  },
  {
    "text": "Directed graphs Definition A directed graph or digraph G is a triple consisting of a vertex set V (G), an edge set E(G), and a function assigning each edge an ordered pair of vertices. The first vertex of the ordered pair is the tail of the edge, and the second is the head ; together, they are the endpoints. We say that an edge is an edge from its tail to its head. Definition In a digraph, a loop is an edge whose endpoints are equal. Multiple edges are edges having the same ordered pair of endpoints. A digraph is simple if each ordered pair is the head and tail of at most one edge ; one loop may be present at each vertex. In a simple digraph, we write uv for an edge with tail u and head v. If there is an edge from u to v, then v is a successor of u, and u is a predecessor of v. We write u → v for “there is an edge from u to v”. Omar Saadi (College of Computing) Algorithmic Foundations 3 Computer Science School 4 / 16",
    "source": "Chapter3_AlgoFoundations3.pdf",
    "page": 4
  },
  {
    "text": "Directed graphs Example : Digraph of a Markov chain Consider a system that can be in n possible states s1, s2, ··· , sn. After being in the state si , the system will go to state sj with probability Pij . Note that for each state si , we have P j Pij = 1. The digraph G representing this Markov chain is such that : V (G) = {s1, s2, ··· , sn} si sj ∈ E(G) iff Pij > 0, in this case the edge si sj has a weight Pij . Definition : We say that a graph (or digraph) G is weighted if we associate to each edge a value, called a weight. Example : Suppose that weather has two states : good (G) and bad (B). Air masses move slowly enough that tomorrow’s weather tends to be like today’s. In most places, storms don’t linger long, so we might have transition probabilities as follows : Omar Saadi (College of Computing) Algorithmic Foundations 3 Computer Science School 5 / 16",
    "source": "Chapter3_AlgoFoundations3.pdf",
    "page": 5
  },
  {
    "text": "Directed graphs Definition A digraph is a path if it is a simple digraph whose vertices can be linearly ordered so that there is an edge with tail u and head v if and only if v immediately follows u in the vertex ordering. A cycle is defined similarly using an ordering of the vertices on a circle. Definition The underlying graph of a digraph D is the graph G obtained by treating the edges of D as unordered pairs ; the vertex set and edge set remain the same, and the endpoints of an edge are the same in G as in D, but in G they become an unordered pair. Omar Saadi (College of Computing) Algorithmic Foundations 3 Computer Science School 6 / 16",
    "source": "Chapter3_AlgoFoundations3.pdf",
    "page": 6
  },
  {
    "text": "Directed graphs Definition The definitions of subgraph, isomorphism and decomposition are the same for graphs and digraphs. In the adjacency matrix A(G) of a digraph G, the entry in position i, j is the number of edges from vi to vj . In the incidence matrix M(G) of a loopless digraph G, we set mij = 1 if vi is the tail of ej and mij = −1 if vi is the head of ej . Example : Omar Saadi (College of Computing) Algorithmic Foundations 3 Computer Science School 7 / 16",
    "source": "Chapter3_AlgoFoundations3.pdf",
    "page": 7
  },
  {
    "text": "Directed graphs Definition A digraph is weakly connected if its underlying graph is connected. A digraph is strongly connected or strong if for each ordered pair u, v of vertices, there is a path from u to v. The strong components of a digraph are its maximal strong subgraphs. Examples : As a digraph, an n-vertex path has n strong components, but a cycle has only one strong component. In the diagraph below, the three circled subdigraphs are the strong components : Omar Saadi (College of Computing) Algorithmic Foundations 3 Computer Science School 8 / 16",
    "source": "Chapter3_AlgoFoundations3.pdf",
    "page": 8
  },
  {
    "text": "Directed graphs Vertex degrees Definition Let v be a vertex in a digraph. The outdegree d+(v) is the number of edges with tail v. The indegree d−(v) is the number of edges with head v. The out-neighborhood or successor set N+(v) is {x ∈ V (G) : v → x}. The in-neighborhood or predecessor set N−(v) is {x ∈ V (G) : x → v}. The minimum and maximum indegree are δ−(G) and ∆ −(G) ; for outdegree we use δ+(G) and ∆ +(G). Proposition In a digraph G, P v∈V (G) d+(v) = |E(G)| = P v∈V (G) d−(v). Proof : Every edge has exactly one tail and exactly one head. Remark : In a graph, the minimum and maximum degree are denoted δ(G) and ∆( G), and we have P v∈V (G) d(v) = 2|E(G)|. ∆(G) is also called the degree of the graph. Omar Saadi (College of Computing) Algorithmic Foundations 3 Computer Science School 9 / 16",
    "source": "Chapter3_AlgoFoundations3.pdf",
    "page": 9
  },
  {
    "text": "Directed graphs Eulerian digraphs The definitions of trail, walk, circuit, and the connection relation are the same in graphs and digraphs when we list edges as ordered pairs of vertices. Definition An Eulerian trail in a digraph (or graph) is a trail containing all edges. An Eulerian circuit is a closed trail containing all edges. A digraph is Eulerian if it has an Eulerian circuit. Omar Saadi (College of Computing) Algorithmic Foundations 3 Computer Science School 10 / 16",
    "source": "Chapter3_AlgoFoundations3.pdf",
    "page": 10
  },
  {
    "text": "Directed graphs Characterization of an Eulerian digraph Lemma If G is a digraph withδ+(G) ≥ 1, then G contains a cycle. The same conclusion holds whenδ−(G) ≥ 1. Proof : Consider a maximal path in G. Theorem A digraph is Eulerian if and only ifd+(v) = d−(v) for each vertexv and the underlying graph has at most one nontrivial component. Omar Saadi (College of Computing) Algorithmic Foundations 3 Computer Science School 11 / 16",
    "source": "Chapter3_AlgoFoundations3.pdf",
    "page": 11
  },
  {
    "text": "Coloring of graphs Outline 1 Directed graphs 2 Coloring of graphs Omar Saadi (College of Computing) Algorithmic Foundations 3 Computer Science School 12 / 16",
    "source": "Chapter3_AlgoFoundations3.pdf",
    "page": 12
  },
  {
    "text": "Coloring of graphs Definition A k-coloring of a graph G is a labeling f : V (G) → S, where |S| = k. The labels are colors; the vertices of one color form a color class. A k-coloring is proper if adjacent vertices have different labels. A graph is k-colorable if it has a proper k-coloring. The chromatic number χ(G) is the least k such that G is k-colorable. If χ(G) = k, we say that G is k-chromatic. Remark In a proper coloring, each color class is an independent set, so G is k-colorable if and only if V (G) is the union of k independent sets. Thus “k-colorable” and “ k-partite” have the same meaning. Omar Saadi (College of Computing) Algorithmic Foundations 3 Computer Science School 13 / 16",
    "source": "Chapter3_AlgoFoundations3.pdf",
    "page": 13
  },
  {
    "text": "Coloring of graphs Example Since a graph is 2-colorable if and only if it is bipartite, and C5 is not bipartite (because it contains an odd cycle), then C5 has a chromatic number at least 3. Since C5 is 3-colorable, as shown below, it has a chromatic number exactly 3. Omar Saadi (College of Computing) Algorithmic Foundations 3 Computer Science School 14 / 16",
    "source": "Chapter3_AlgoFoundations3.pdf",
    "page": 14
  },
  {
    "text": "Coloring of graphs Lower bounds onχ(G) Recall : The independence number of a graph G, written α(G), is the biggest size of an independent subset of V (G). Definition The clique number of a graph G, written ω(G), is the maximum size of a clique in G. Proposition For every graph G with n vertices, we have χ(G) ≥ ω(G) and χ(G) ≥ n α(G). Proof : Omar Saadi (College of Computing) Algorithmic Foundations 3 Computer Science School 15 / 16",
    "source": "Chapter3_AlgoFoundations3.pdf",
    "page": 15
  },
  {
    "text": "Coloring of graphs An upper bound onχ(G) Algorithm : (Greedy coloring) The greedy coloring relative to a vertex ordering {v1, ··· , vn} of V (G) by the color set S is obtained by coloring vertices in the order v1, ··· , vn, assigning to vi the color with the smallest index in S that was not already used to color the neighbors of vi that were already colored. Proposition For every graph G, we have χ(G) ≤ ∆(G) + 1. Recall that ∆( G) is the degree of the graph G (i.e. the largest degree of its vertices). Proof : The greedy coloring doesn’t use more that ∆( G) + 1 colors. Remark : Note that the bound ∆( G) + 1 is optimal in the case of complete graphs and cycles. Omar Saadi (College of Computing) Algorithmic Foundations 3 Computer Science School 16 / 16",
    "source": "Chapter3_AlgoFoundations3.pdf",
    "page": 16
  },
  {
    "text": "Chapter 4 : Trees Omar Saadi omar.saadi@um6p.ma UM6P - College of Computing 1st year of the engineering degree of UM6P-CS Academic year 2024-2025 Omar Saadi (College of Computing) Algorithmic Foundations 3 (GA) Computer Science School 1 / 26",
    "source": "Chapter4_AlgoFoundations_GA.pdf",
    "page": 1
  },
  {
    "text": "Outline 1 Basic properties 2 Distance in trees and graphs 3 Binary trees 4 Huffman coding More details on this chapter can be found in Sect. 2.1 and (last part of) Sect 2.3 of D. B. West’s book. Omar Saadi (College of Computing) Algorithmic Foundations 3 (GA) Computer Science School 2 / 26",
    "source": "Chapter4_AlgoFoundations_GA.pdf",
    "page": 2
  },
  {
    "text": "Basic properties Outline 1 Basic properties 2 Distance in trees and graphs 3 Binary trees 4 Huffman coding Omar Saadi (College of Computing) Algorithmic Foundations 3 (GA) Computer Science School 3 / 26",
    "source": "Chapter4_AlgoFoundations_GA.pdf",
    "page": 3
  },
  {
    "text": "Basic properties Definition We say that a graph is acyclic if it doesn’t contain any cycle. A forest is an acyclic graph. A tree is a connected acyclic graph. A leaf (or pendant vertex) is a vertex of degree 1. Definition A spanning subgraph of G is a subgraph with vertex set V (G). A spanning tree is a spanning subgraph that is a tree. Omar Saadi (College of Computing) Algorithmic Foundations 3 (GA) Computer Science School 4 / 26",
    "source": "Chapter4_AlgoFoundations_GA.pdf",
    "page": 4
  },
  {
    "text": "Basic properties Examples The following graph is a forest (no cycles). The following two graphs are trees (connected and no cycles). Their union is a forest. A tree is a connected forest, and every component of a forest is a tree. A graph with no cycles has no odd cycles ; hence trees and forests are bipartite. Omar Saadi (College of Computing) Algorithmic Foundations 3 (GA) Computer Science School 5 / 26",
    "source": "Chapter4_AlgoFoundations_GA.pdf",
    "page": 5
  },
  {
    "text": "Basic properties Examples (Cont.) Paths are trees. A tree is a path if and only if its maximum degree is 2. A graph that is a tree has exactly one spanning tree ; the full graph itself. Remark A spanning subgraph of G doesn’t need to be connected, and a connected subgraph of G doesn’t need to be a spanning subgraph. For example : If n(G) ≥ 2, then the subgraph with vertex set V (G) and edge set ∅ is spanning but not connected. If n(G) ≥ 3, then a subgraph consisting of one edge and its endpoints is connected but not necessarily spanning. Omar Saadi (College of Computing) Algorithmic Foundations 3 (GA) Computer Science School 6 / 26",
    "source": "Chapter4_AlgoFoundations_GA.pdf",
    "page": 6
  },
  {
    "text": "Basic properties Lemma Every tree with at least two vertices has at least two leaves. Deleting a leaf from an n-vertex tree produces a tree with n − 1 vertices. Proof : Consider the endpoints of a maximal path and use the connectivity and the acyclicity properties of the tree. Remark This lemma implies that every tree with more than one vertex arises from a smaller tree by adding a vertex of degree 1. This remark is useful for induction reasoning when dealing with trees : growing an n + 1-vertex tree from an arbitrary n-vertex tree by adding a new neighbor at an arbitrary old vertex generates all trees with n + 1 vertices. Omar Saadi (College of Computing) Algorithmic Foundations 3 (GA) Computer Science School 7 / 26",
    "source": "Chapter4_AlgoFoundations_GA.pdf",
    "page": 7
  },
  {
    "text": "Basic properties Characterizations of trees Theorem For an n-vertex graph G (with n ≥ 1), the following assertions are equivalent (and characterize the trees with n vertices) : 1 G is connected and has no cycles. 2 G is connected and has n - 1 edges. 3 G has n − 1 edges and no cycles. 4 For all u, v ∈ V (G), G has exactly one u, v-path. Proof : First prove the equivalence of 1 , 2, and 3 by proving that any two properties among the set {connected, acyclic, n − 1 edges} imply the third one. Then prove that 1 and 4 are equivalent. Omar Saadi (College of Computing) Algorithmic Foundations 3 (GA) Computer Science School 8 / 26",
    "source": "Chapter4_AlgoFoundations_GA.pdf",
    "page": 8
  },
  {
    "text": "Basic properties Corollary 1 Every edge of a tree is a cut-edge. 2 Adding one edge to a tree forms exactly one cycle. 3 Every connected graph contains a spanning tree. Proof : Omar Saadi (College of Computing) Algorithmic Foundations 3 (GA) Computer Science School 9 / 26",
    "source": "Chapter4_AlgoFoundations_GA.pdf",
    "page": 9
  },
  {
    "text": "Basic properties Proposition If T , T ′ are spanning trees of a connected graph G and e ∈ E(T ) − E(T ′), then there is an edge e′ ∈ E(T ′) − E(T ) such that T − e + e′ is a spanning tree of G. Their is also an edge e′′ ∈ E(T ′) − E(T ) such that T ′ + e − e′′ is a spanning tree of G. Proof : Consider the two components of T − e for the first result, and consider the unique cycle obtained by adding e to T ′ for the second result. Omar Saadi (College of Computing) Algorithmic Foundations 3 (GA) Computer Science School 10 / 26",
    "source": "Chapter4_AlgoFoundations_GA.pdf",
    "page": 10
  },
  {
    "text": "Distance in trees and graphs Outline 1 Basic properties 2 Distance in trees and graphs 3 Binary trees 4 Huffman coding Omar Saadi (College of Computing) Algorithmic Foundations 3 (GA) Computer Science School 11 / 26",
    "source": "Chapter4_AlgoFoundations_GA.pdf",
    "page": 11
  },
  {
    "text": "Distance in trees and graphs Definition If G has a u, v-path, then the distance from u to v, written dG (u, v) or simply d(u, v), is the least length of a u, v-path. If G has no such path, then d(u, v) = ∞. The diameter (diam(G)) is max u,v∈V (G) d(u, v). The eccentricity of a vertex u, written ϵ(u), is max v∈V (G) d(u, v). The radius of a graph G, written rad( G), is min u∈V (G) ϵ(u). Remarks The diameter equals the maximum of the vertex eccentricities. In a disconnected graph, the diameter and radius (and every eccentricity) are infinite, because distance between vertices in different components is infinite. We use the word “diameter” due to its use in geometry, where it is the greatest distance between two elements of a set. Omar Saadi (College of Computing) Algorithmic Foundations 3 (GA) Computer Science School 12 / 26",
    "source": "Chapter4_AlgoFoundations_GA.pdf",
    "page": 12
  },
  {
    "text": "Distance in trees and graphs Examples The Petersen graph has diameter 2, since nonadjacent vertices have a common neighbor. The cycle Cn has diameter ⌊n/2⌋. In these two examples, every vertex has the same eccentricity, and diam(G) = rad(G). Every path in a tree is the shortest (the only) path between its endpoints, so the diameter of a tree is the length of its longest path. In the graph below, each vertex is labeled with its eccentricity. The radius is 2, the diameter is 4, and the length of the longest path is 7. Omar Saadi (College of Computing) Algorithmic Foundations 3 (GA) Computer Science School 13 / 26",
    "source": "Chapter4_AlgoFoundations_GA.pdf",
    "page": 13
  },
  {
    "text": "Distance in trees and graphs Proposition If G is a simple graph, then diam( G) ≥ 3 ⇒ diam(G) ≤ 3. Proof : Use the fact that if diam( G) ≥ 3 then there exist nonadjacent vertices u, v ∈ V (G) with no common neighbor. Omar Saadi (College of Computing) Algorithmic Foundations 3 (GA) Computer Science School 14 / 26",
    "source": "Chapter4_AlgoFoundations_GA.pdf",
    "page": 14
  },
  {
    "text": "Distance in trees and graphs Definition The center of a graph G is the subgraph induced by the vertices of minimum eccentricity. Remark : The center of a graph is the full graph if and only if the radius and diameter are equal. Theorem (Jordan [1869]) The center of a tree is a vertex or an edge. Proof : We use induction on the number of vertices in a tree T , where we obtain a smaller tree T ′ by deleting every leaf of T . Use the fact that ∀u ∈ V (T ′), ϵT′ (u) = ϵT (u) − 1. Omar Saadi (College of Computing) Algorithmic Foundations 3 (GA) Computer Science School 15 / 26",
    "source": "Chapter4_AlgoFoundations_GA.pdf",
    "page": 15
  },
  {
    "text": "Binary trees Outline 1 Basic properties 2 Distance in trees and graphs 3 Binary trees 4 Huffman coding Omar Saadi (College of Computing) Algorithmic Foundations 3 (GA) Computer Science School 16 / 26",
    "source": "Chapter4_AlgoFoundations_GA.pdf",
    "page": 16
  },
  {
    "text": "Binary trees Definition A rooted tree is a tree with one vertex r chosen as root. For each vertex v, let P(v) be the unique v, r-path. The parent of v is its neighbor on P(v) ; its children are its other neighbors. Its ancestors are the vertices of P(v) − v. Its descendants are the vertices u such that P(u) contains v. The leaves are the vertices with no children. A rooted plane tree or planted tree is a rooted tree with a left-to-right ordering specified for the children of each vertex. Example : Omar Saadi (College of Computing) Algorithmic Foundations 3 (GA) Computer Science School 17 / 26",
    "source": "Chapter4_AlgoFoundations_GA.pdf",
    "page": 17
  },
  {
    "text": "Binary trees Definition A binary tree is a rooted plane tree where each vertex has at most two children, and each child of a vertex is designated as its left child or right child. The subtrees rooted at the children of the root are the left subtree and the right subtree of the tree. A k-ary tree allows each vertex up to k children. Remark Binary trees permit storage of data for quick access. We store each item at a leaf and access it by following the path from the root. We encode the path by recording 0 when we move to a left child and 1 when we move to a right child. For each leaf, the search time is the length of its code word. Omar Saadi (College of Computing) Algorithmic Foundations 3 (GA) Computer Science School 18 / 26",
    "source": "Chapter4_AlgoFoundations_GA.pdf",
    "page": 18
  },
  {
    "text": "Huffman coding Outline 1 Basic properties 2 Distance in trees and graphs 3 Binary trees 4 Huffman coding Omar Saadi (College of Computing) Algorithmic Foundations 3 (GA) Computer Science School 19 / 26",
    "source": "Chapter4_AlgoFoundations_GA.pdf",
    "page": 19
  },
  {
    "text": "Huffman coding In a text file, each character is stored as a binary list. The classical way to encode characters is to use the ASCII code. It encodes each character using 7 bits. This allows to encode 128 characters that appear in text files. The ASCII table is the following : Omar Saadi (College of Computing) Algorithmic Foundations 3 (GA) Computer Science School 20 / 26",
    "source": "Chapter4_AlgoFoundations_GA.pdf",
    "page": 20
  },
  {
    "text": "Huffman coding Prefix-free coding Objective : Given a text file, we want to encode each character appearing in that text using a binary list with the goal of minimizing the total number of bits needed to store this text file. The length of code words may vary ; so we need a way to recognize the end of the current word. Idea : If no code word is an initial portion of another, we can easily recover our characters. We can do this by going through the list of bits (from left to right), and at each time that a sublist of bits correspond to a code of a character we make the transformation “bits to character”, and start again for the remaining bits. Definition : We call such coding a prefix-free coding. Example : If we have only three characters a, b, c with the following prefix-free coding a ↔ 1, b ↔ 01, c ↔ 00, then we can get the following encodings : aabacbc ↔ 11011000100 and ccbaac ↔ 0000011100. Omar Saadi (College of Computing) Algorithmic Foundations 3 (GA) Computer Science School 21 / 26",
    "source": "Chapter4_AlgoFoundations_GA.pdf",
    "page": 21
  },
  {
    "text": "Huffman coding Remark Under the prefix-free condition, the binary code words correspond to the leaves of a binary tree using the left/right encoding described above. Input : The text file uses n characters c1, ··· , cn with probabilities of occurrence p1, ··· , pn respectively. Notice that pi is the number of occurrences of ci divided by the total number N of characters in the text. Goal : Construct the binary tree such that the bit lengths l1, ··· , ln assigned to the leaves c1, ··· , cn are such that : The expected length of a code word X i∈[n] pi li is minimal. Notice that we are minimizing indeed the total length of the encoding N × P i∈[n] pi li . Omar Saadi (College of Computing) Algorithmic Foundations 3 (GA) Computer Science School 22 / 26",
    "source": "Chapter4_AlgoFoundations_GA.pdf",
    "page": 22
  },
  {
    "text": "Huffman coding Huffman’s Algorithm Input : Weights (frequencies or probabilities) p1, ··· , pn. Output : Prefix-free code (equivalently, a binary tree). Idea : Infrequent items should have longer codes ; put infrequent items deeper by combining them into parent vertices. Initial case : When n = 2, the optimal length is one, with 0 and 1 being the codes assigned to the two items (the tree has a root and two leaves). Recursion : When n > 2, replace the two items with the smallest probabilities p, p′ with a single item q of weight p + p′. Treat the smaller set as a problem with n − 1 items. After solving it, give children with weights p, p′ to the resulting leaf with weight q. Equivalently, replace the code computed for the combined item q with its extensions by 1 and 0, assigned to the items that were replaced. Notice that each vertex that is not a leaf has exactly two children. Omar Saadi (College of Computing) Algorithmic Foundations 3 (GA) Computer Science School 23 / 26",
    "source": "Chapter4_AlgoFoundations_GA.pdf",
    "page": 23
  },
  {
    "text": "Huffman coding Example Consider eight items with frequencies 5 , 1, 1, 7, 8, 2, 3, 6. Huffman’s algorithm will output the tree below in the left, working from the bottom up. The values of the vertices are the (combined) frequencies. We obtain code words as shown in the tree below in the right. In their original order, the items have code words 100, 00000, 00001, 01, 11, 0001, 001, and 101. The expected length of a code word is L = P i pi li = 90/33. Omar Saadi (College of Computing) Algorithmic Foundations 3 (GA) Computer Science School 24 / 26",
    "source": "Chapter4_AlgoFoundations_GA.pdf",
    "page": 24
  },
  {
    "text": "Huffman coding Optimality of Huffman coding Theorem Given a probability distribution {p1, ··· , pn} on n items, Huffman’s algorithm produces the prefix-free code with minimum expected length. Proof We use induction on n. Basis step : n = 2. The algorithm encodes each item as a single bit, which is optimal. Induction step : n > 2. Suppose that the algorithm computes the optimal code when given a distribution for n − 1 items. With n items, an optimal binary tree T must assign the items with probabilities p1 ≥ ··· ≥pn to leaves in increasing order of depth, because otherwise we can exchange two items and get a strictly better encoding. Therefore the two items with the smallest probabilities are assigned to leaves of greatest depth. Since permuting items at a given depth doesn’t change the expected length, we may assume that items n and n −1 appear as siblings at greatest depth in T . Omar Saadi (College of Computing) Algorithmic Foundations 3 (GA) Computer Science School 25 / 26",
    "source": "Chapter4_AlgoFoundations_GA.pdf",
    "page": 25
  },
  {
    "text": "Huffman coding Proof (Cont.) Let T ′ be the tree obtained from T by deleting these leaves, and let {q1, ··· , qn−1} be the probability distribution obtained by replacing {pn−1, pn} by qn−1 = pn−1 + pn, and ∀i ∈ [n − 2], qi = pi . The tree T ′ yields a code for {qi }. Notice that, if k is the depth of the leaf assigned of weight qn−1 in T ′, we have length(T ) = X i∈[n] pi li = X i∈[n−2] pi li + (k + 1)(pn−1 + pn) = P i∈[n−1] qi li + qn−1 = length( T ′) + qn−1 . So it suffices that T ′ is optimal to get that T is optimal because they have the same length up to the fixed constant qn−1. By the induction hypothesis, an optimal choice for T ′ is obtained by applying Huffman’s algorithm to {qi }. Since the replacement of {pn−1, pn} by qn−1 is exactly the first step of Huffman’s Algorithm for {pi }, we conclude that Huffman’s algorithm generates the optimal tree T for {pi }. Omar Saadi (College of Computing) Algorithmic Foundations 3 (GA) Computer Science School 26 / 26",
    "source": "Chapter4_AlgoFoundations_GA.pdf",
    "page": 26
  },
  {
    "text": "Chapter 5 : Minimum Spanning Tree Omar Saadi omar.saadi@um6p.ma UM6P - College of Computing 1st year of the engineering degree of UM6P-CS Academic year 2024-2025 Omar Saadi (College of Computing) Algorithmic Foundations (GA) Computer Science School 1 / 16",
    "source": "Chapter5_AlgoFoundations_GA.pdf",
    "page": 1
  },
  {
    "text": "Outline 1 Introduction 2 Kruskal’s Algorithm 3 Prim’s Algorithm Omar Saadi (College of Computing) Algorithmic Foundations (GA) Computer Science School 2 / 16",
    "source": "Chapter5_AlgoFoundations_GA.pdf",
    "page": 2
  },
  {
    "text": "Introduction Outline 1 Introduction 2 Kruskal’s Algorithm 3 Prim’s Algorithm Omar Saadi (College of Computing) Algorithmic Foundations (GA) Computer Science School 3 / 16",
    "source": "Chapter5_AlgoFoundations_GA.pdf",
    "page": 3
  },
  {
    "text": "Introduction Introduction Definition A weighted graphis a graph with numerical labels on the edges. For a weighted connected graph, a minimal spanning treeis a spanning tree that has the smallest (total) weight possible. Example : Consider a graph such that : Each vertex is a city When two cities can be connected by a road, then there is an edge between them in the graph, and its weight is the cost of constructing that road. Here, connecting all the cities with the smallest total construction cost is exaclty the minimum spanning tree problem. In the following the weights are allowed to be positive or negative. Omar Saadi (College of Computing) Algorithmic Foundations (GA) Computer Science School 4 / 16",
    "source": "Chapter5_AlgoFoundations_GA.pdf",
    "page": 4
  },
  {
    "text": "Kruskal’s Algorithm Outline 1 Introduction 2 Kruskal’s Algorithm 3 Prim’s Algorithm Omar Saadi (College of Computing) Algorithmic Foundations (GA) Computer Science School 5 / 16",
    "source": "Chapter5_AlgoFoundations_GA.pdf",
    "page": 5
  },
  {
    "text": "Kruskal’s Algorithm Kruskal’s Algorithm Input : A weighted connected graph. Idea : Maintain an acyclic spanning subgraph H, enlarging it by edges with low weight to form a spanning tree. Initialization :Set V (H) = V (G) and E(H) = ∅. Iteration :If the next cheapest edge joins two components of H, then include it in H ; otherwise, discard it. Terminate when H is connected. Omar Saadi (College of Computing) Algorithmic Foundations (GA) Computer Science School 6 / 16",
    "source": "Chapter5_AlgoFoundations_GA.pdf",
    "page": 6
  },
  {
    "text": "Kruskal’s Algorithm Example The following example shows a weighted connected graph with the spanning tree given by Kruskal’s algorithm. The edges are add the following order : 1 , 2, 3, 4, 7, 10. Remark Unsophisticated locally optimal heuristics are called greedy algorithms. They usually don’t guarantee optimal solutions, but Kruskal’s algorithm is an example of a greedy algorithm that gives an optimal solution (see next theorem). Omar Saadi (College of Computing) Algorithmic Foundations (GA) Computer Science School 7 / 16",
    "source": "Chapter5_AlgoFoundations_GA.pdf",
    "page": 7
  },
  {
    "text": "Kruskal’s Algorithm Example The following example shows a weighted connected graph with the spanning tree given by Kruskal’s algorithm. The edges are add the following order : 1 , 2, 3, 4, 7, 10. Remark Unsophisticated locally optimal heuristics are called greedy algorithms. They usually don’t guarantee optimal solutions, but Kruskal’s algorithm is an example of a greedy algorithm that gives an optimal solution (see next theorem). Omar Saadi (College of Computing) Algorithmic Foundations (GA) Computer Science School 7 / 16",
    "source": "Chapter5_AlgoFoundations_GA.pdf",
    "page": 8
  },
  {
    "text": "Kruskal’s Algorithm Theorem (Kruskal [1956]) In a connected weighted graphG, Kruskal’s algorithm constructs a minimum-weight spanning tree. Proof First we show that the algorithm produces a tree. Indeed, at each iteration, while H is not yet connected, there is at least an edge that connects two different components of H (because G is connected), so at each iteration an edge is added to H. It becomes connected exactely after adding n − 1 edges, and so it becomes a tree. Let T be the resulting tree, and let T′ be a spanning tree of minimum weight. If T = T′, we are done. If T ̸= T′, let e be the first edge chosen for T that is not in T′. Adding e to T′ creates one cycle C. Since T has no cycle, C has an edge e′ ̸∈ E(T). Consider the spanning tree T′′ = T′ + e − e′. Omar Saadi (College of Computing) Algorithmic Foundations (GA) Computer Science School 8 / 16",
    "source": "Chapter5_AlgoFoundations_GA.pdf",
    "page": 9
  },
  {
    "text": "Kruskal’s Algorithm Proof (Cont.) Since T′ contains e′ and all the edges of T chosen before e, then e′ could be added to T when the algorithm choosed e (without creating a cycle). So both e′ and e were available when the algorithm choosed e, and hence w(e) ≤ w(e′). Thus T′′ = T′ + e − e′ is a spanning tree with weight that doesn’t exceed the weight of T′ and that agrees with T for a longer initial list of edges than T′ does. In particular T′′ is also a minimum spanning tree. Repeating this argument yields a minimum-weight spanning tree that agrees completely with T. Therefore T is a minimum spanning tree. Omar Saadi (College of Computing) Algorithmic Foundations (GA) Computer Science School 9 / 16",
    "source": "Chapter5_AlgoFoundations_GA.pdf",
    "page": 10
  },
  {
    "text": "Kruskal’s Algorithm Let n = |V (G)| and m = |E(G)|. Implementation steps : First sort the m edge weights. Maintain for each vertex the label of the component containing it. Add the next cheapest edge if its endpoints have different labels, and merge the two components by changing the label of each vertex in the smaller component to the label of the larger one. Complexity : Since the size of the component at least doubles when a label changes (we are changing the smaller one), each label changes at most log2(n) times, and the total number of changes is at most n log2(n). With this labeling method, the running time for large graphs depends on the time to sort m weights of the edges, which is O(m log(m)). Omar Saadi (College of Computing) Algorithmic Foundations (GA) Computer Science School 10 / 16",
    "source": "Chapter5_AlgoFoundations_GA.pdf",
    "page": 11
  },
  {
    "text": "Prim’s Algorithm Outline 1 Introduction 2 Kruskal’s Algorithm 3 Prim’s Algorithm Omar Saadi (College of Computing) Algorithmic Foundations (GA) Computer Science School 11 / 16",
    "source": "Chapter5_AlgoFoundations_GA.pdf",
    "page": 12
  },
  {
    "text": "Prim’s Algorithm Input : A weighted connected graph. Idea : Growing a subgraph H from one isolated vertex by iteratively adding the cheapest edge from a vertex already reached to a vertex not yet reached to form a spanning tree. Initialization :V (H) = {v} and E(H) = ∅ for a given starting vertex v. Iteration :Add to H the cheapest edge (with its other endpoint) from a vertex already in H to a vertex outside H. Terminate when H is spanning. Example : In the above example, if we start from the vertex in the bottom left, we obtain the same spanning tree in the following order of edges : 10 , 2, 4, 3, 7, 1. Omar Saadi (College of Computing) Algorithmic Foundations (GA) Computer Science School 12 / 16",
    "source": "Chapter5_AlgoFoundations_GA.pdf",
    "page": 13
  },
  {
    "text": "Prim’s Algorithm Input : A weighted connected graph. Idea : Growing a subgraph H from one isolated vertex by iteratively adding the cheapest edge from a vertex already reached to a vertex not yet reached to form a spanning tree. Initialization :V (H) = {v} and E(H) = ∅ for a given starting vertex v. Iteration :Add to H the cheapest edge (with its other endpoint) from a vertex already in H to a vertex outside H. Terminate when H is spanning. Example : In the above example, if we start from the vertex in the bottom left, we obtain the same spanning tree in the following order of edges : 10 , 2, 4, 3, 7, 1. Omar Saadi (College of Computing) Algorithmic Foundations (GA) Computer Science School 12 / 16",
    "source": "Chapter5_AlgoFoundations_GA.pdf",
    "page": 14
  },
  {
    "text": "Prim’s Algorithm Theorem (Jarnik [1930], Prim [1957]) In a connected weighted graphG, Prim’s algorithm constructs a minimum-weight spanning tree. Proof First we show that the algorithm produces a spanning tree. Indeed, at each iteration, we are keeping H connected, and we are adding one edge that does not create any cycle. So H is always a tree. After exactely n − 1 iterations, it becomes a spanning tree. Using the same idea of proof as Kruskal’s algorithm : Let T be the resulting tree from Prim’s algorithm, and let T′ be a spanning tree of minimum weight. If T = T′, we are done. If T ̸= T′, let e be the first edge chosen (at iteration i) for T that is not in T′. At iteration i − 1, we denote the set obtain by {v0, ··· , vi −1}. the edge e connects {v0, ··· , vi −1} to V (G) \\ {v0, ··· , vi −1}. Omar Saadi (College of Computing) Algorithmic Foundations (GA) Computer Science School 13 / 16",
    "source": "Chapter5_AlgoFoundations_GA.pdf",
    "page": 15
  },
  {
    "text": "Prim’s Algorithm Proof (Cont.) Now, adding e to T′ creates one cycle C. So, C − e is a path from a vertex in {v0, ··· , vi −1} to a vertex in V (G) \\ {v0, ··· , vi −1}. Therefore, C − e contains an edge e′ that connects {v0, ··· , vi −1} to V (G) \\ {v0, ··· , vi −1}. Then e′ could be added to T when the algorithm choosed e (at iteration i), and hence w(e) ≤ w(e′). Thus T′′ = T′ + e − e′ is a spanning tree with weight that doesn’t exceed the weight of T′ and that agrees with T for a longer initial list of edges than T′ does. In particular T′′ is also a minimum spanning tree. Repeating this argument yields a minimum-weight spanning tree that agrees completely with T. Therefore T is a minimum spanning tree. Omar Saadi (College of Computing) Algorithmic Foundations (GA) Computer Science School 14 / 16",
    "source": "Chapter5_AlgoFoundations_GA.pdf",
    "page": 16
  },
  {
    "text": "Prim’s Algorithm Implementation steps and complexity : Using the weights matrix w(u, v) giving the weight of the edge ( u, v) (with w(u, v) = +∞ if (u, v) ̸∈ E(H)). Idea : Construct and update a first list d[v], v ̸∈ H, with d[v] being the cheapest weight of an edge that connects v to some vertex u already in H. Also consider a second list p[v], v ̸∈ H, with p[v] = u being the neighbor in H to which v is connected with the cheapest weight d[v]. The steps and the corresponding complexity are as follows (next slide) : Omar Saadi (College of Computing) Algorithmic Foundations (GA) Computer Science School 15 / 16",
    "source": "Chapter5_AlgoFoundations_GA.pdf",
    "page": 17
  },
  {
    "text": "Prim’s Algorithm 1 Start with H = v0 (any initial vertex v0). [This takes O(1)] 2 For all v ̸= v0, initialize d[v] = w(v0, v), and p[v] = v0 if (v, v0) ∈ E(H) and p[v] = ∅ otherwise. [This takes O(n)] 3 While H is still not spanning do the following : Extract the cheapest weight in d corresponding to some vertex vi . Remove d[vi ] and p[vi ] from d and p. Add the vertex vi and the edge (p[vi ], vi ) to H. [this takes O(n)]. Update d and p : For all neighbours v of vi such that v ̸∈ H, do : If w(v, vi ) < d[v], then d[v] = w(v, vi ) and p[v] = vi . [this takes O(deg(vi ) = O(n)]. Complexity :Combining the above complexities, we get that the total time complexity is O(n2). Remark :This complexity can be improved to O(m log(n)) using other data structures to represent the graph (where m = |E(G)|). Omar Saadi (College of Computing) Algorithmic Foundations (GA) Computer Science School 16 / 16",
    "source": "Chapter5_AlgoFoundations_GA.pdf",
    "page": 18
  },
  {
    "text": "Chapter 6 : Breadth-First Search and Depth-First Search Omar Saadi omar.saadi@um6p.ma UM6P - College of Computing 1st year of the engineering degree of UM6P-CS Academic year 2024-2025 Omar Saadi (College of Computing) Algorithmic Foundations (GA) Computer Science School 1 / 24",
    "source": "Chapter6_AlgoFoundations_GA.pdf",
    "page": 1
  },
  {
    "text": "Outline 1 Breadth-First Search (BFS) 2 Depth-First Search (DFS) Omar Saadi (College of Computing) Algorithmic Foundations (GA) Computer Science School 2 / 24",
    "source": "Chapter6_AlgoFoundations_GA.pdf",
    "page": 2
  },
  {
    "text": "Breadth-First Search (BFS) Outline 1 Breadth-First Search (BFS) 2 Depth-First Search (DFS) Omar Saadi (College of Computing) Algorithmic Foundations (GA) Computer Science School 3 / 24",
    "source": "Chapter6_AlgoFoundations_GA.pdf",
    "page": 3
  },
  {
    "text": "Breadth-First Search (BFS) Introduction Given a graph G, there are several problems one wants to solve related to the connectivity of the graph. Those include the following : Given a pair of vertices ( u, v), is there a path in G from u to v ? Given a pair of vertices ( u, v), what is the distance d(u, v) and a shortest path from u to v ? Given a vertex s, find d(s, v) for all v ∈ V (G) and a shortest path tree* containing a shortest path from s to every v ∈ V . * : A shortest path tree is a tree of G where the unique path from s to any vertex v inside this tree is a shortest path from s to v in G. Omar Saadi (College of Computing) Algorithmic Foundations (GA) Computer Science School 4 / 24",
    "source": "Chapter6_AlgoFoundations_GA.pdf",
    "page": 4
  },
  {
    "text": "Breadth-First Search (BFS) Introduction Given a graph G, there are several problems one wants to solve related to the connectivity of the graph. Those include the following : Given a pair of vertices ( u, v), is there a path in G from u to v ? Given a pair of vertices ( u, v), what is the distance d(u, v) and a shortest path from u to v ? Given a vertex s, find d(s, v) for all v ∈ V (G) and a shortest path tree* containing a shortest path from s to every v ∈ V . * : A shortest path tree is a tree of G where the unique path from s to any vertex v inside this tree is a shortest path from s to v in G. Omar Saadi (College of Computing) Algorithmic Foundations (GA) Computer Science School 4 / 24",
    "source": "Chapter6_AlgoFoundations_GA.pdf",
    "page": 5
  },
  {
    "text": "Breadth-First Search (BFS) Introduction Given a graph G, there are several problems one wants to solve related to the connectivity of the graph. Those include the following : Given a pair of vertices ( u, v), is there a path in G from u to v ? Given a pair of vertices ( u, v), what is the distance d(u, v) and a shortest path from u to v ? Given a vertex s, find d(s, v) for all v ∈ V (G) and a shortest path tree* containing a shortest path from s to every v ∈ V . * : A shortest path tree is a tree of G where the unique path from s to any vertex v inside this tree is a shortest path from s to v in G. Omar Saadi (College of Computing) Algorithmic Foundations (GA) Computer Science School 4 / 24",
    "source": "Chapter6_AlgoFoundations_GA.pdf",
    "page": 6
  },
  {
    "text": "Breadth-First Search (BFS) Introduction Given a graph G, there are several problems one wants to solve related to the connectivity of the graph. Those include the following : Given a pair of vertices ( u, v), is there a path in G from u to v ? Given a pair of vertices ( u, v), what is the distance d(u, v) and a shortest path from u to v ? Given a vertex s, find d(s, v) for all v ∈ V (G) and a shortest path tree* containing a shortest path from s to every v ∈ V . * : A shortest path tree is a tree of G where the unique path from s to any vertex v inside this tree is a shortest path from s to v in G. Omar Saadi (College of Computing) Algorithmic Foundations (GA) Computer Science School 4 / 24",
    "source": "Chapter6_AlgoFoundations_GA.pdf",
    "page": 7
  },
  {
    "text": "Breadth-First Search (BFS) Shortest Paths Tree Question How to return a shortest path from the source vertex s to every vertex v in the graph ? Problem Many paths could have length Ω( |V |), so returning every path could require Ω(|V |2) time. Idea For every v ∈ V , store its parent P(v) in a shortest path from s to v. This set of parents has an Ω( |V |) size and comprises a shortest paths tree. It provides a reversed shortest paths back to s from every vertex v reachable from s Omar Saadi (College of Computing) Algorithmic Foundations (GA) Computer Science School 5 / 24",
    "source": "Chapter6_AlgoFoundations_GA.pdf",
    "page": 8
  },
  {
    "text": "Breadth-First Search (BFS) Shortest Paths Tree Question How to return a shortest path from the source vertex s to every vertex v in the graph ? Problem Many paths could have length Ω( |V |), so returning every path could require Ω(|V |2) time. Idea For every v ∈ V , store its parent P(v) in a shortest path from s to v. This set of parents has an Ω( |V |) size and comprises a shortest paths tree. It provides a reversed shortest paths back to s from every vertex v reachable from s Omar Saadi (College of Computing) Algorithmic Foundations (GA) Computer Science School 5 / 24",
    "source": "Chapter6_AlgoFoundations_GA.pdf",
    "page": 9
  },
  {
    "text": "Breadth-First Search (BFS) Shortest Paths Tree Question How to return a shortest path from the source vertex s to every vertex v in the graph ? Problem Many paths could have length Ω( |V |), so returning every path could require Ω(|V |2) time. Idea For every v ∈ V , store its parent P(v) in a shortest path from s to v. This set of parents has an Ω( |V |) size and comprises a shortest paths tree. It provides a reversed shortest paths back to s from every vertex v reachable from s Omar Saadi (College of Computing) Algorithmic Foundations (GA) Computer Science School 5 / 24",
    "source": "Chapter6_AlgoFoundations_GA.pdf",
    "page": 10
  },
  {
    "text": "Breadth-First Search (BFS) Breadth-First Search (BFS) We want to : Store d(s, v) and P(v) in Set data structures mapping vertices v to distance and parent respectively. (If no path from s to v, do not store v in P and set d(s, v) to ∞). Idea : Explore graph nodes in increasing order of distance from s. Goal :Compute level sets Li = {v | v ∈ V and d(s, v) = i} (i.e., all vertices at distance i from s). Claims : Every vertex v ∈ Li must be adjacent to some vertex u ∈ Li−1 (i.e., v ∈ Adj(u)). No vertex that is in Lj for some j < i, appears in Li . Invariant :d(s, v) and P(v) have been computed correctly for all v in any Lj for j < i. Omar Saadi (College of Computing) Algorithmic Foundations (GA) Computer Science School 6 / 24",
    "source": "Chapter6_AlgoFoundations_GA.pdf",
    "page": 11
  },
  {
    "text": "Breadth-First Search (BFS) Breadth-First Search (BFS) We want to : Store d(s, v) and P(v) in Set data structures mapping vertices v to distance and parent respectively. (If no path from s to v, do not store v in P and set d(s, v) to ∞). Idea : Explore graph nodes in increasing order of distance from s. Goal :Compute level sets Li = {v | v ∈ V and d(s, v) = i} (i.e., all vertices at distance i from s). Claims : Every vertex v ∈ Li must be adjacent to some vertex u ∈ Li−1 (i.e., v ∈ Adj(u)). No vertex that is in Lj for some j < i, appears in Li . Invariant :d(s, v) and P(v) have been computed correctly for all v in any Lj for j < i. Omar Saadi (College of Computing) Algorithmic Foundations (GA) Computer Science School 6 / 24",
    "source": "Chapter6_AlgoFoundations_GA.pdf",
    "page": 12
  },
  {
    "text": "Breadth-First Search (BFS) Breadth-First Search (BFS) We want to : Store d(s, v) and P(v) in Set data structures mapping vertices v to distance and parent respectively. (If no path from s to v, do not store v in P and set d(s, v) to ∞). Idea : Explore graph nodes in increasing order of distance from s. Goal :Compute level sets Li = {v | v ∈ V and d(s, v) = i} (i.e., all vertices at distance i from s). Claims : Every vertex v ∈ Li must be adjacent to some vertex u ∈ Li−1 (i.e., v ∈ Adj(u)). No vertex that is in Lj for some j < i, appears in Li . Invariant :d(s, v) and P(v) have been computed correctly for all v in any Lj for j < i. Omar Saadi (College of Computing) Algorithmic Foundations (GA) Computer Science School 6 / 24",
    "source": "Chapter6_AlgoFoundations_GA.pdf",
    "page": 13
  },
  {
    "text": "Breadth-First Search (BFS) Breadth-First Search (BFS) We want to : Store d(s, v) and P(v) in Set data structures mapping vertices v to distance and parent respectively. (If no path from s to v, do not store v in P and set d(s, v) to ∞). Idea : Explore graph nodes in increasing order of distance from s. Goal :Compute level sets Li = {v | v ∈ V and d(s, v) = i} (i.e., all vertices at distance i from s). Claims : Every vertex v ∈ Li must be adjacent to some vertex u ∈ Li−1 (i.e., v ∈ Adj(u)). No vertex that is in Lj for some j < i, appears in Li . Invariant :d(s, v) and P(v) have been computed correctly for all v in any Lj for j < i. Omar Saadi (College of Computing) Algorithmic Foundations (GA) Computer Science School 6 / 24",
    "source": "Chapter6_AlgoFoundations_GA.pdf",
    "page": 14
  },
  {
    "text": "Breadth-First Search (BFS) BFS Algorithm Base case (i = 0) : L0 = {s}, d(s, s) = 0, P(s) = None Inductive Step : To compute Li : For every vertex u ∈ Li−1 : For every vertex v ∈ Adj(u) that does not appear in any Lj for j < i, do : Add v to Li , set d(s, v) = i, and set P(v) = u. Repeatedly compute Li from Lj for j < i for increasing i until Li is the empty set. Set d(s, v) = ∞ for any v ∈ V for which d(s, v) was not set. Omar Saadi (College of Computing) Algorithmic Foundations (GA) Computer Science School 7 / 24",
    "source": "Chapter6_AlgoFoundations_GA.pdf",
    "page": 15
  },
  {
    "text": "Breadth-First Search (BFS) Remarks The principle of the above Breadth-First Search algorithm is : Start with the source vertex s Visit his neighbours Then visit the neighbours of its neighbours (that were not yet explored) and so on ··· until visiting all reachable vertices from s. Recall that the largest distance from a fixed vertex u to another vertex is the eccentricity ϵ(u). Hence BFS started at u allows to compute this eccentricity. So we can compute the diameter of a graph by running Breadth-First Search from each vertex. BFS can be applied in its same above format for directed graphs. In this case, the neighbors of u are taken in the directed sens. BFS can also be applied to the particular case of trees to do a tree traversal. Omar Saadi (College of Computing) Algorithmic Foundations (GA) Computer Science School 8 / 24",
    "source": "Chapter6_AlgoFoundations_GA.pdf",
    "page": 16
  },
  {
    "text": "Breadth-First Search (BFS) Remarks The principle of the above Breadth-First Search algorithm is : Start with the source vertex s Visit his neighbours Then visit the neighbours of its neighbours (that were not yet explored) and so on ··· until visiting all reachable vertices from s. Recall that the largest distance from a fixed vertex u to another vertex is the eccentricity ϵ(u). Hence BFS started at u allows to compute this eccentricity. So we can compute the diameter of a graph by running Breadth-First Search from each vertex. BFS can be applied in its same above format for directed graphs. In this case, the neighbors of u are taken in the directed sens. BFS can also be applied to the particular case of trees to do a tree traversal. Omar Saadi (College of Computing) Algorithmic Foundations (GA) Computer Science School 8 / 24",
    "source": "Chapter6_AlgoFoundations_GA.pdf",
    "page": 17
  },
  {
    "text": "Breadth-First Search (BFS) Remarks The principle of the above Breadth-First Search algorithm is : Start with the source vertex s Visit his neighbours Then visit the neighbours of its neighbours (that were not yet explored) and so on ··· until visiting all reachable vertices from s. Recall that the largest distance from a fixed vertex u to another vertex is the eccentricity ϵ(u). Hence BFS started at u allows to compute this eccentricity. So we can compute the diameter of a graph by running Breadth-First Search from each vertex. BFS can be applied in its same above format for directed graphs. In this case, the neighbors of u are taken in the directed sens. BFS can also be applied to the particular case of trees to do a tree traversal. Omar Saadi (College of Computing) Algorithmic Foundations (GA) Computer Science School 8 / 24",
    "source": "Chapter6_AlgoFoundations_GA.pdf",
    "page": 18
  },
  {
    "text": "Breadth-First Search (BFS) Remarks The principle of the above Breadth-First Search algorithm is : Start with the source vertex s Visit his neighbours Then visit the neighbours of its neighbours (that were not yet explored) and so on ··· until visiting all reachable vertices from s. Recall that the largest distance from a fixed vertex u to another vertex is the eccentricity ϵ(u). Hence BFS started at u allows to compute this eccentricity. So we can compute the diameter of a graph by running Breadth-First Search from each vertex. BFS can be applied in its same above format for directed graphs. In this case, the neighbors of u are taken in the directed sens. BFS can also be applied to the particular case of trees to do a tree traversal. Omar Saadi (College of Computing) Algorithmic Foundations (GA) Computer Science School 8 / 24",
    "source": "Chapter6_AlgoFoundations_GA.pdf",
    "page": 19
  },
  {
    "text": "Breadth-First Search (BFS) Example Performing BFS search on the following tree, starting from the vertex 1, leads to the next traversal of the tree : Omar Saadi (College of Computing) Algorithmic Foundations (GA) Computer Science School 9 / 24",
    "source": "Chapter6_AlgoFoundations_GA.pdf",
    "page": 20
  },
  {
    "text": "Breadth-First Search (BFS) Proposition Breadth-first search correctly computes all d(s, v) and P(v) for every v ∈ V . Proof : Straightforward by an induction over i. Proposition Breadth-first search runs in O(|V | + |E|) time (i.e. linear time). Proof : (Next slide) Omar Saadi (College of Computing) Algorithmic Foundations (GA) Computer Science School 10 / 24",
    "source": "Chapter6_AlgoFoundations_GA.pdf",
    "page": 21
  },
  {
    "text": "Breadth-First Search (BFS) Proposition Breadth-first search correctly computes all d(s, v) and P(v) for every v ∈ V . Proof : Straightforward by an induction over i. Proposition Breadth-first search runs in O(|V | + |E|) time (i.e. linear time). Proof : (Next slide) Omar Saadi (College of Computing) Algorithmic Foundations (GA) Computer Science School 10 / 24",
    "source": "Chapter6_AlgoFoundations_GA.pdf",
    "page": 22
  },
  {
    "text": "Breadth-First Search (BFS) Proof Algorithm adds each vertex u to at most one level Li and spends O(1) time for each v ∈ Adj(u). Time complexity upper bounded by O(1) × P u∈V deg(u) = O(|E|) Spend O(|V |) at end to assign d(s, v) for vertices v ∈ V not reachable from s ⇒ Breadth-first search runs in linear time O(|V | + |E|) Omar Saadi (College of Computing) Algorithmic Foundations (GA) Computer Science School 11 / 24",
    "source": "Chapter6_AlgoFoundations_GA.pdf",
    "page": 23
  },
  {
    "text": "Breadth-First Search (BFS) Proof Algorithm adds each vertex u to at most one level Li and spends O(1) time for each v ∈ Adj(u). Time complexity upper bounded by O(1) × P u∈V deg(u) = O(|E|) Spend O(|V |) at end to assign d(s, v) for vertices v ∈ V not reachable from s ⇒ Breadth-first search runs in linear time O(|V | + |E|) Omar Saadi (College of Computing) Algorithmic Foundations (GA) Computer Science School 11 / 24",
    "source": "Chapter6_AlgoFoundations_GA.pdf",
    "page": 24
  },
  {
    "text": "Breadth-First Search (BFS) Application : checking strongly connectivity Problem Given a directed graph, check if it is strongly connected or not. Solution 1 (a na ¨ ıve one) Perform BFS starting from every vertex in the graph. If each BFS call visits every other vertex in the graph, then the graph is strongly connected. Complexity :We are performing BFS |V | times, and each call of BFS need O(|V | + |E|), so the total complexity is O(|V |(|V | + |E|)). Omar Saadi (College of Computing) Algorithmic Foundations (GA) Computer Science School 12 / 24",
    "source": "Chapter6_AlgoFoundations_GA.pdf",
    "page": 25
  },
  {
    "text": "Breadth-First Search (BFS) Application : checking strongly connectivity Problem Given a directed graph, check if it is strongly connected or not. Solution 1 (a na ¨ ıve one) Perform BFS starting from every vertex in the graph. If each BFS call visits every other vertex in the graph, then the graph is strongly connected. Complexity :We are performing BFS |V | times, and each call of BFS need O(|V | + |E|), so the total complexity is O(|V |(|V | + |E|)). Omar Saadi (College of Computing) Algorithmic Foundations (GA) Computer Science School 12 / 24",
    "source": "Chapter6_AlgoFoundations_GA.pdf",
    "page": 26
  },
  {
    "text": "Breadth-First Search (BFS) Solution 2 Choose a vertex u, and perform BFS starting from u. Reverse the direction of all edges in the digraph G, and perform again BFS starting from the same vertex u. Proposition The graph is strongly connected if and only if both calls of BFS visit every vertex in the graph. Proof : There is a path from u to every other vertex v, and also a path from every other vertex v to u. Complexity :We are performing BFS twice, so the total complexity is O(|V | + |E|). Remark :this problem can be solved also by DFS (described below) instead of BFS. Omar Saadi (College of Computing) Algorithmic Foundations (GA) Computer Science School 13 / 24",
    "source": "Chapter6_AlgoFoundations_GA.pdf",
    "page": 27
  },
  {
    "text": "Breadth-First Search (BFS) Solution 2 Choose a vertex u, and perform BFS starting from u. Reverse the direction of all edges in the digraph G, and perform again BFS starting from the same vertex u. Proposition The graph is strongly connected if and only if both calls of BFS visit every vertex in the graph. Proof : There is a path from u to every other vertex v, and also a path from every other vertex v to u. Complexity :We are performing BFS twice, so the total complexity is O(|V | + |E|). Remark :this problem can be solved also by DFS (described below) instead of BFS. Omar Saadi (College of Computing) Algorithmic Foundations (GA) Computer Science School 13 / 24",
    "source": "Chapter6_AlgoFoundations_GA.pdf",
    "page": 28
  },
  {
    "text": "Breadth-First Search (BFS) Solution 2 Choose a vertex u, and perform BFS starting from u. Reverse the direction of all edges in the digraph G, and perform again BFS starting from the same vertex u. Proposition The graph is strongly connected if and only if both calls of BFS visit every vertex in the graph. Proof : There is a path from u to every other vertex v, and also a path from every other vertex v to u. Complexity :We are performing BFS twice, so the total complexity is O(|V | + |E|). Remark :this problem can be solved also by DFS (described below) instead of BFS. Omar Saadi (College of Computing) Algorithmic Foundations (GA) Computer Science School 13 / 24",
    "source": "Chapter6_AlgoFoundations_GA.pdf",
    "page": 29
  },
  {
    "text": "Depth-First Search (DFS) Outline 1 Breadth-First Search (BFS) 2 Depth-First Search (DFS) Omar Saadi (College of Computing) Algorithmic Foundations (GA) Computer Science School 14 / 24",
    "source": "Chapter6_AlgoFoundations_GA.pdf",
    "page": 30
  },
  {
    "text": "Depth-First Search (DFS) Depth-First Search (DFS) Goal : Search a graph from a vertex s, like BFS. Solve Single Source Reachability : i.e. Given a vertex s (source), identify all the vertices u reachable from s and provide a path from s to u (not necessarily a shortest path). Return parent tree of parent pointers back to s (like BFS, but not necessarily shortest paths). Idea : Visit outgoing adjacencies recursively, but never revisit a vertex. Meaning that : follow any path until you get stuck, backtrack until finding an unexplored path to explore. Omar Saadi (College of Computing) Algorithmic Foundations (GA) Computer Science School 15 / 24",
    "source": "Chapter6_AlgoFoundations_GA.pdf",
    "page": 31
  },
  {
    "text": "Depth-First Search (DFS) Depth-First Search (DFS) Goal : Search a graph from a vertex s, like BFS. Solve Single Source Reachability : i.e. Given a vertex s (source), identify all the vertices u reachable from s and provide a path from s to u (not necessarily a shortest path). Return parent tree of parent pointers back to s (like BFS, but not necessarily shortest paths). Idea : Visit outgoing adjacencies recursively, but never revisit a vertex. Meaning that : follow any path until you get stuck, backtrack until finding an unexplored path to explore. Omar Saadi (College of Computing) Algorithmic Foundations (GA) Computer Science School 15 / 24",
    "source": "Chapter6_AlgoFoundations_GA.pdf",
    "page": 32
  },
  {
    "text": "Depth-First Search (DFS) DFS algorithm : P(s) = None, then run visit( s), where the function “visit” is defined recursively as follows : visit(u) : for every v ∈ Adj(u) that does not appear in P : Set P(v) = u and recursively call visit( v). DFS finishes visiting vertex u (for use later !). Remarks : The principle of the above Depth-First Search algorithm is : Start with the source vertex s Visit one of his neighbours Then visit one neighbour of this neighbour (that was not yet explored) and so on ··· until visiting all reachable vertices from s (when no more neighbors exist backtrack until finding an unexplored path to explore). DFS can also be applied to directed graphs. Here the neighbors of u are taken in the directed sens. DFS can also be applied to the particular case of trees to do a tree traversal. Omar Saadi (College of Computing) Algorithmic Foundations (GA) Computer Science School 16 / 24",
    "source": "Chapter6_AlgoFoundations_GA.pdf",
    "page": 33
  },
  {
    "text": "Depth-First Search (DFS) DFS algorithm : P(s) = None, then run visit( s), where the function “visit” is defined recursively as follows : visit(u) : for every v ∈ Adj(u) that does not appear in P : Set P(v) = u and recursively call visit( v). DFS finishes visiting vertex u (for use later !). Remarks : The principle of the above Depth-First Search algorithm is : Start with the source vertex s Visit one of his neighbours Then visit one neighbour of this neighbour (that was not yet explored) and so on ··· until visiting all reachable vertices from s (when no more neighbors exist backtrack until finding an unexplored path to explore). DFS can also be applied to directed graphs. Here the neighbors of u are taken in the directed sens. DFS can also be applied to the particular case of trees to do a tree traversal. Omar Saadi (College of Computing) Algorithmic Foundations (GA) Computer Science School 16 / 24",
    "source": "Chapter6_AlgoFoundations_GA.pdf",
    "page": 34
  },
  {
    "text": "Depth-First Search (DFS) DFS algorithm : P(s) = None, then run visit( s), where the function “visit” is defined recursively as follows : visit(u) : for every v ∈ Adj(u) that does not appear in P : Set P(v) = u and recursively call visit( v). DFS finishes visiting vertex u (for use later !). Remarks : The principle of the above Depth-First Search algorithm is : Start with the source vertex s Visit one of his neighbours Then visit one neighbour of this neighbour (that was not yet explored) and so on ··· until visiting all reachable vertices from s (when no more neighbors exist backtrack until finding an unexplored path to explore). DFS can also be applied to directed graphs. Here the neighbors of u are taken in the directed sens. DFS can also be applied to the particular case of trees to do a tree traversal. Omar Saadi (College of Computing) Algorithmic Foundations (GA) Computer Science School 16 / 24",
    "source": "Chapter6_AlgoFoundations_GA.pdf",
    "page": 35
  },
  {
    "text": "Depth-First Search (DFS) Example Performing DFS search on the same tree as the example above, starting from the vertex 1, leads to the next traversal of the tree (left), to compare to the previous BFS traversal (right) : Figure – DFS traversal Figure – BFS traversal Omar Saadi (College of Computing) Algorithmic Foundations (GA) Computer Science School 17 / 24",
    "source": "Chapter6_AlgoFoundations_GA.pdf",
    "page": 36
  },
  {
    "text": "Depth-First Search (DFS) Proposition DFS visits v and correctly sets P(v) for every vertex v reachable from s. Proof Induction on k, for the result on only vertices within distance k from the source vertex s. Base case ( k = 0) : P(s) is set correctly for s and s is visited. Inductive step : Consider vertex v with d(s, v) = k + 1. Consider vertex u, the second to last vertex on some shortest path from s to v. By induction, since d(s, u) = k, DFS visits u and sets P(u) correctly. While visiting u, DFS considers v ∈ Adj(u). Either v is in P, so has already been visited, or v will be visited while visiting u. In either case, v will be visited by DFS and added correctly to P. Omar Saadi (College of Computing) Algorithmic Foundations (GA) Computer Science School 18 / 24",
    "source": "Chapter6_AlgoFoundations_GA.pdf",
    "page": 37
  },
  {
    "text": "Depth-First Search (DFS) Proposition DFS visits v and correctly sets P(v) for every vertex v reachable from s. Proof Induction on k, for the result on only vertices within distance k from the source vertex s. Base case ( k = 0) : P(s) is set correctly for s and s is visited. Inductive step : Consider vertex v with d(s, v) = k + 1. Consider vertex u, the second to last vertex on some shortest path from s to v. By induction, since d(s, u) = k, DFS visits u and sets P(u) correctly. While visiting u, DFS considers v ∈ Adj(u). Either v is in P, so has already been visited, or v will be visited while visiting u. In either case, v will be visited by DFS and added correctly to P. Omar Saadi (College of Computing) Algorithmic Foundations (GA) Computer Science School 18 / 24",
    "source": "Chapter6_AlgoFoundations_GA.pdf",
    "page": 38
  },
  {
    "text": "Depth-First Search (DFS) Proposition DFS visits v and correctly sets P(v) for every vertex v reachable from s. Proof Induction on k, for the result on only vertices within distance k from the source vertex s. Base case ( k = 0) : P(s) is set correctly for s and s is visited. Inductive step : Consider vertex v with d(s, v) = k + 1. Consider vertex u, the second to last vertex on some shortest path from s to v. By induction, since d(s, u) = k, DFS visits u and sets P(u) correctly. While visiting u, DFS considers v ∈ Adj(u). Either v is in P, so has already been visited, or v will be visited while visiting u. In either case, v will be visited by DFS and added correctly to P. Omar Saadi (College of Computing) Algorithmic Foundations (GA) Computer Science School 18 / 24",
    "source": "Chapter6_AlgoFoundations_GA.pdf",
    "page": 39
  },
  {
    "text": "Depth-First Search (DFS) Proposition DFS visits v and correctly sets P(v) for every vertex v reachable from s. Proof Induction on k, for the result on only vertices within distance k from the source vertex s. Base case ( k = 0) : P(s) is set correctly for s and s is visited. Inductive step : Consider vertex v with d(s, v) = k + 1. Consider vertex u, the second to last vertex on some shortest path from s to v. By induction, since d(s, u) = k, DFS visits u and sets P(u) correctly. While visiting u, DFS considers v ∈ Adj(u). Either v is in P, so has already been visited, or v will be visited while visiting u. In either case, v will be visited by DFS and added correctly to P. Omar Saadi (College of Computing) Algorithmic Foundations (GA) Computer Science School 18 / 24",
    "source": "Chapter6_AlgoFoundations_GA.pdf",
    "page": 40
  },
  {
    "text": "Depth-First Search (DFS) Proposition DFS visits v and correctly sets P(v) for every vertex v reachable from s. Proof Induction on k, for the result on only vertices within distance k from the source vertex s. Base case ( k = 0) : P(s) is set correctly for s and s is visited. Inductive step : Consider vertex v with d(s, v) = k + 1. Consider vertex u, the second to last vertex on some shortest path from s to v. By induction, since d(s, u) = k, DFS visits u and sets P(u) correctly. While visiting u, DFS considers v ∈ Adj(u). Either v is in P, so has already been visited, or v will be visited while visiting u. In either case, v will be visited by DFS and added correctly to P. Omar Saadi (College of Computing) Algorithmic Foundations (GA) Computer Science School 18 / 24",
    "source": "Chapter6_AlgoFoundations_GA.pdf",
    "page": 41
  },
  {
    "text": "Depth-First Search (DFS) Running time of DFS Algorithm visits each vertex u at most once and spends O(1) time for each v ∈ Adj(u). Total complexity upper bounded by O(1) × P u deg(u) = O(|E|). Unlike BFS, we don’t return a distance for each vertex, so DFS runs in O(|E|) time. Remark :If we want to identify also the vertices that are not reachable from s, i.e. that does not appear in P, the complexity becomes O(|V | + |E|), like BFS. Omar Saadi (College of Computing) Algorithmic Foundations (GA) Computer Science School 19 / 24",
    "source": "Chapter6_AlgoFoundations_GA.pdf",
    "page": 42
  },
  {
    "text": "Depth-First Search (DFS) Running time of DFS Algorithm visits each vertex u at most once and spends O(1) time for each v ∈ Adj(u). Total complexity upper bounded by O(1) × P u deg(u) = O(|E|). Unlike BFS, we don’t return a distance for each vertex, so DFS runs in O(|E|) time. Remark :If we want to identify also the vertices that are not reachable from s, i.e. that does not appear in P, the complexity becomes O(|V | + |E|), like BFS. Omar Saadi (College of Computing) Algorithmic Foundations (GA) Computer Science School 19 / 24",
    "source": "Chapter6_AlgoFoundations_GA.pdf",
    "page": 43
  },
  {
    "text": "Depth-First Search (DFS) Running time of DFS Algorithm visits each vertex u at most once and spends O(1) time for each v ∈ Adj(u). Total complexity upper bounded by O(1) × P u deg(u) = O(|E|). Unlike BFS, we don’t return a distance for each vertex, so DFS runs in O(|E|) time. Remark :If we want to identify also the vertices that are not reachable from s, i.e. that does not appear in P, the complexity becomes O(|V | + |E|), like BFS. Omar Saadi (College of Computing) Algorithmic Foundations (GA) Computer Science School 19 / 24",
    "source": "Chapter6_AlgoFoundations_GA.pdf",
    "page": 44
  },
  {
    "text": "Depth-First Search (DFS) Running time of DFS Algorithm visits each vertex u at most once and spends O(1) time for each v ∈ Adj(u). Total complexity upper bounded by O(1) × P u deg(u) = O(|E|). Unlike BFS, we don’t return a distance for each vertex, so DFS runs in O(|E|) time. Remark :If we want to identify also the vertices that are not reachable from s, i.e. that does not appear in P, the complexity becomes O(|V | + |E|), like BFS. Omar Saadi (College of Computing) Algorithmic Foundations (GA) Computer Science School 19 / 24",
    "source": "Chapter6_AlgoFoundations_GA.pdf",
    "page": 45
  },
  {
    "text": "Depth-First Search (DFS) Full-BFS and Full-DFS Suppose we want to explore entire graph, not just vertices reachable from one vertex : A simple BFS or DFS from one vertex is not sufficient especially in the case of non connected graph (non strongly connected digraph). Idea :Repeat the graph search algorithm (BFS or DFS) on any unvisited vertex. This unvisited vertex will allow to explore another connected component (or strongly connected component in a digraph). We call this algorithm a Full-BFS or a Full-DFS. Notice that they are providing parent forests instead of parent trees. Remark :A Full-BFS (or a Full-DFS) allows to identify the connected components (or the strongly connected components in a digraph). Complexity :Since we are going through all the vertices, the time complexity of both algorithms Full-BFS and Full-DFS is O(|V | + |E|). Omar Saadi (College of Computing) Algorithmic Foundations (GA) Computer Science School 20 / 24",
    "source": "Chapter6_AlgoFoundations_GA.pdf",
    "page": 46
  },
  {
    "text": "Depth-First Search (DFS) Full-BFS and Full-DFS Suppose we want to explore entire graph, not just vertices reachable from one vertex : A simple BFS or DFS from one vertex is not sufficient especially in the case of non connected graph (non strongly connected digraph). Idea :Repeat the graph search algorithm (BFS or DFS) on any unvisited vertex. This unvisited vertex will allow to explore another connected component (or strongly connected component in a digraph). We call this algorithm a Full-BFS or a Full-DFS. Notice that they are providing parent forests instead of parent trees. Remark :A Full-BFS (or a Full-DFS) allows to identify the connected components (or the strongly connected components in a digraph). Complexity :Since we are going through all the vertices, the time complexity of both algorithms Full-BFS and Full-DFS is O(|V | + |E|). Omar Saadi (College of Computing) Algorithmic Foundations (GA) Computer Science School 20 / 24",
    "source": "Chapter6_AlgoFoundations_GA.pdf",
    "page": 47
  },
  {
    "text": "Depth-First Search (DFS) Full-BFS and Full-DFS Suppose we want to explore entire graph, not just vertices reachable from one vertex : A simple BFS or DFS from one vertex is not sufficient especially in the case of non connected graph (non strongly connected digraph). Idea :Repeat the graph search algorithm (BFS or DFS) on any unvisited vertex. This unvisited vertex will allow to explore another connected component (or strongly connected component in a digraph). We call this algorithm a Full-BFS or a Full-DFS. Notice that they are providing parent forests instead of parent trees. Remark :A Full-BFS (or a Full-DFS) allows to identify the connected components (or the strongly connected components in a digraph). Complexity :Since we are going through all the vertices, the time complexity of both algorithms Full-BFS and Full-DFS is O(|V | + |E|). Omar Saadi (College of Computing) Algorithmic Foundations (GA) Computer Science School 20 / 24",
    "source": "Chapter6_AlgoFoundations_GA.pdf",
    "page": 48
  },
  {
    "text": "Depth-First Search (DFS) Application : Topological Sort Definition A Directed Acyclic Graph(DAG) is a directed graph that contains no directed cycles. A Topological Orderof a graph G = (V , E) is an ordering f on the vertices such that : every edge ( u, v) ∈ E satisfies f (u) < f (v). Recall (ES4 - ex7) : A directed graph admits a topological ordering if and only if it is a DAG. Question : How to find a topological order ? Definition A Finishing Orderis the order in which a Full-DFS finishes visiting each vertex in G. Omar Saadi (College of Computing) Algorithmic Foundations (GA) Computer Science School 21 / 24",
    "source": "Chapter6_AlgoFoundations_GA.pdf",
    "page": 49
  },
  {
    "text": "Depth-First Search (DFS) Application : Topological Sort Definition A Directed Acyclic Graph(DAG) is a directed graph that contains no directed cycles. A Topological Orderof a graph G = (V , E) is an ordering f on the vertices such that : every edge ( u, v) ∈ E satisfies f (u) < f (v). Recall (ES4 - ex7) : A directed graph admits a topological ordering if and only if it is a DAG. Question : How to find a topological order ? Definition A Finishing Orderis the order in which a Full-DFS finishes visiting each vertex in G. Omar Saadi (College of Computing) Algorithmic Foundations (GA) Computer Science School 21 / 24",
    "source": "Chapter6_AlgoFoundations_GA.pdf",
    "page": 50
  },
  {
    "text": "Depth-First Search (DFS) Application : Topological Sort Definition A Directed Acyclic Graph(DAG) is a directed graph that contains no directed cycles. A Topological Orderof a graph G = (V , E) is an ordering f on the vertices such that : every edge ( u, v) ∈ E satisfies f (u) < f (v). Recall (ES4 - ex7) : A directed graph admits a topological ordering if and only if it is a DAG. Question : How to find a topological order ? Definition A Finishing Orderis the order in which a Full-DFS finishes visiting each vertex in G. Omar Saadi (College of Computing) Algorithmic Foundations (GA) Computer Science School 21 / 24",
    "source": "Chapter6_AlgoFoundations_GA.pdf",
    "page": 51
  },
  {
    "text": "Depth-First Search (DFS) Application : Topological Sort Proposition A digraph G = (V , E) is a DAG if and only if the reverse of a finishing order of a Full-DFS is a topological order. Proof ⇐) This implication is trivial. ⇒) Need to prove, for every edge ( u, v) ∈ E that u is ordered before v, i.e. that the visit to v finishes before the visit to u finishes. Two cases : If u is visited before v : Before visit to u finishes, will visit v (via (u, v) or otherwise). Thus the visit to v finishes before finishing the visit to u. If v is visited before u : u can’t be reached from v since graph is acyclic. Thus the visit to v finishes before visiting u. Omar Saadi (College of Computing) Algorithmic Foundations (GA) Computer Science School 22 / 24",
    "source": "Chapter6_AlgoFoundations_GA.pdf",
    "page": 52
  },
  {
    "text": "Depth-First Search (DFS) Application : Cycle detection Full-DFS will find a topological order iff the graph G = (V , E) is acyclic. If G contains a cycle then reverse finishing order for Full-DFS (called f ) is not a topological order. Meaning that there exists ( u, v) ∈ E such that Full-DFS finishes visiting u before it finishes visiting v (i.e. f (v) < f (u)). Proposition Let G be a diagraph that contains a cycle, and ( u, v) ∈ E such that Full-DFS finishes visiting u before it finishes visiting v, then this Full-DFS contains a path from v to u constructed by considering the reversed path back to s from vertex v. Adding the edge ( u, v) to this path we obtain a cycle. Omar Saadi (College of Computing) Algorithmic Foundations (GA) Computer Science School 23 / 24",
    "source": "Chapter6_AlgoFoundations_GA.pdf",
    "page": 53
  },
  {
    "text": "Depth-First Search (DFS) Application : Cycle detection Proof (of Prop.) Necessarily v is visited before u (because otherwise using the edge ( u, v), v will be visited and finished before u). Since Full-DFS finishes visiting u before v this means that during the visit of v, Full-DFS starts and finishes the visit of u, and this means that v is an ancestor of u, giving a path from v to u. Complexity :We need to run Full-DFS needing O(|V | + |E|). Then, we need to find an edge ( u, v) such that f (v) < f (u) and this will take O(|E|) to go through all the edges. Finally we need to go through the reverse path from v to u, and this will need at most O(|V |). Finally, the total complexity is O(|V | + |E|). Omar Saadi (College of Computing) Algorithmic Foundations (GA) Computer Science School 24 / 24",
    "source": "Chapter6_AlgoFoundations_GA.pdf",
    "page": 54
  },
  {
    "text": "Chapter 7 : Shortest Path Problem - Dijkstra’s Algorithm Omar Saadi omar.saadi@um6p.ma UM6P - College of Computing 1st year of the engineering degree of UM6P-CS Academic year 2024-2025 Omar Saadi (College of Computing) Algorithmic Foundations 3 (GA) Computer Science School 1 / 12",
    "source": "Chapter7_AlgoFoundations3_GA.pdf",
    "page": 1
  },
  {
    "text": "Outline 1 Introduction 2 Dijkstra’s Algorithm Omar Saadi (College of Computing) Algorithmic Foundations 3 (GA) Computer Science School 2 / 12",
    "source": "Chapter7_AlgoFoundations3_GA.pdf",
    "page": 2
  },
  {
    "text": "Introduction Outline 1 Introduction 2 Dijkstra’s Algorithm Omar Saadi (College of Computing) Algorithmic Foundations 3 (GA) Computer Science School 3 / 12",
    "source": "Chapter7_AlgoFoundations3_GA.pdf",
    "page": 3
  },
  {
    "text": "Introduction Shortest path problem Some real-world problems : How can you find the shortest routes from your home to every place in town ? How to find the cheapest flight(s) from Casablanca to Hong Kong allowing stopovers ? How to find the fastest driving route (Google Maps) ? The internet : how to find the fastest path to send information through a network of routers ? All these problems can be modeled using weighted (di)graphs, and solving the shortest path problem. Omar Saadi (College of Computing) Algorithmic Foundations 3 (GA) Computer Science School 4 / 12",
    "source": "Chapter7_AlgoFoundations3_GA.pdf",
    "page": 4
  },
  {
    "text": "Introduction Framework We have a graph (or digraph) G = (V , E). Each edge ( u, v) ∈ E has a nonnegative weight w(u, v) (that represents a distance, a cost, a time, ...). We have a starting vertex s and a destination vertex d. Shortest path problem We want to solve the following problem : minimize P a s,d-path in G w(P), where w(P) is the weight of the path P given as the sum of the weights of the edges forming it. Omar Saadi (College of Computing) Algorithmic Foundations 3 (GA) Computer Science School 5 / 12",
    "source": "Chapter7_AlgoFoundations3_GA.pdf",
    "page": 5
  },
  {
    "text": "Dijkstra’s Algorithm Outline 1 Introduction 2 Dijkstra’s Algorithm Omar Saadi (College of Computing) Algorithmic Foundations 3 (GA) Computer Science School 6 / 12",
    "source": "Chapter7_AlgoFoundations3_GA.pdf",
    "page": 6
  },
  {
    "text": "Dijkstra’s Algorithm Dijkstra’s Algorithm Input :A graph (or digraph) with nonnegative edge weights and a starting vertex s. Output :Distance d(s, t) from s to each other vertex t and a shortest path tree given by identifying the parent P(u) of each vertex u. Key idea :∀t ∈ V , the algorithm computes an estimate d[t] of the distance of t from the source s such that : 1 At any point in time, d[t] ≥ d(s, t), and 2 when t is finished, d[t] = d(s, t). Let w(x, y) = +∞ if (x, y) is not an edge. Omar Saadi (College of Computing) Algorithmic Foundations 3 (GA) Computer Science School 7 / 12",
    "source": "Chapter7_AlgoFoundations3_GA.pdf",
    "page": 7
  },
  {
    "text": "Dijkstra’s Algorithm Dijkstra’s Algorithm Idea : Maintain the set S of vertices to which a shortest path from s is known, enlarging S to include all vertices. To do this, maintain a tentative distance d[t] from s to each t ̸∈ S, being the length of the shortest s, t-path yet found. Initialization :Set S = {s}; d[s] = 0; P(s) = None. For t ̸= s, set d[t] = w(s, t) and if w(s, t) ̸= +∞ then take P(t) = s. Iteration :Select a vertex x ̸∈ S such that d[x] = mint̸∈S d[t]. Add the vertex x to S. For each edge ( x, y) ∈ E such that y ̸∈ S : update d[y] to min{d[y], d[x] + w(x, y)}. If d[y] changes, then update P(y) to x. The iteration continues until S = V (G) or until d[y] = +∞ for every y ̸∈ S. At the end, set d(s, x) = d[x] for all x ∈ V . Omar Saadi (College of Computing) Algorithmic Foundations 3 (GA) Computer Science School 8 / 12",
    "source": "Chapter7_AlgoFoundations3_GA.pdf",
    "page": 8
  },
  {
    "text": "Dijkstra’s Algorithm Lemma 1 For every u, at any point of time d[u] ≥ d(s, u) and d[u] represents the length of some path from s to u. Proof We proceed by induction over the iterations of the algorithm. Base case :we know that d[s] = 0 = d(s, s) and for each vertex t ̸= s we have d[t] = w(s, t) ≥ d(s, t), so we know that the claim holds initially. Induction :when d[u] is changed to d[x] + w(x, u) then (by the induction hypothesis) there is a path from s to x of weight d[x] (that does not contain u) and an edge ( x, u) of weight w(x, u). This means there is a path from s to u of weight d[u] = d[x] + w(x, u). This implies that d[u] is at least the weight of the shortest path = d(s, u). Omar Saadi (College of Computing) Algorithmic Foundations 3 (GA) Computer Science School 9 / 12",
    "source": "Chapter7_AlgoFoundations3_GA.pdf",
    "page": 9
  },
  {
    "text": "Dijkstra’s Algorithm Lemma 2 The assertion d[x] ≤ d[y] for all y ̸∈ S stays true at all points after x is inserted into S. Proof We take F = V \\ S. By absurd, assume that at some point for some y ∈ F we get d[y] < d[x] and let y be the first such y. Before d[y] was updated d [y′] ≥ d[x] for all y′ ∈ F . But then when d[y] was changed, it was due to some neighbor y′ of y in F , such that d[y] = d [y′] + w(y′, y) ≥ d [y′] ≥ d[x], so we get a contradiction. Omar Saadi (College of Computing) Algorithmic Foundations 3 (GA) Computer Science School 10 / 12",
    "source": "Chapter7_AlgoFoundations3_GA.pdf",
    "page": 10
  },
  {
    "text": "Dijkstra’s Algorithm Proposition When vertex x is placed in S, d[x] = d(s, x), and backtracking from x to s using the parent list P yields a shortest path from s to x. Proof We take F = V \\ S. We do an induction on the order of placement of vertices into S. For the base case, s is placed into S where d[s] = d(s, s) = 0 and P(s) = None, so initially, the claim holds. Inductive step :we assume that for all vertices y currently in S, d[y] = d(s, y) and P yields shortest paths for them. Let x be the vertex that will be added to S, i.e. satisfying d[x] = mint̸∈S d[t]. Let p be a shortest path from s to x. Suppose z is the vertex on p closest to x for which d[z] = d(s, z). We know z exists since there is at least one such vertex, namely s, where d[s] = d(s, s). By the choice of z, for every vertex y on p between z (not inclusive) to x (inclusive), d[y] > d(s, y). Omar Saadi (College of Computing) Algorithmic Foundations 3 (GA) Computer Science School 11 / 12",
    "source": "Chapter7_AlgoFoundations3_GA.pdf",
    "page": 11
  },
  {
    "text": "Dijkstra’s Algorithm Proof (Cont.) We have the following two options for z : 1 If z = x, then d[x] = d(s, x) and we are done. 2 Suppose z ̸= x. Then there is a vertex z′ after z on p. We know that d[z] = d(s, z) ≤ d(s, x) ≤ d[x]. Finally, towards a contradiction, suppose d[z] < d[x]. By the choice of x ∈ F we know d[x] = mint∈F d[t]. Thus, since d[z] < d[x], we know z ∈ S. This means the edges out of z, and in particular ( z, z′), were already considered by our algorithm. But this means that d [z′] ≤ d(s, z) + w (z, z′) = d (s, z′), because z is on the shortest path from s to z′. However, this contradicts z being the closest vertex on p to x meeting the criteria d[z] = d(s, z). Thus, the assumption d[z] < d[x] is false and d[x] must equal d(s, x). Note that updating the parent P(y) whenever d[y] is improved insures that at the end P contains the parents in shortest paths with lengths d[x] = d(s, x) for all x ∈ V . Omar Saadi (College of Computing) Algorithmic Foundations 3 (GA) Computer Science School 12 / 12",
    "source": "Chapter7_AlgoFoundations3_GA.pdf",
    "page": 12
  },
  {
    "text": "Chapter 8 : Shortest Path Problem - Bellman-Ford Algorithm Omar Saadi omar.saadi@um6p.ma UM6P - College of Computing 1st year of the engineering degree of UM6P-CS Academic year 2024-2025 Omar Saadi (College of Computing) Algorithmic Foundations 3 Computer Science School 1 / 13",
    "source": "Chapter8_AlgoFoundations_GA.pdf",
    "page": 1
  },
  {
    "text": "Outline 1 Introduction 2 Bellman-Ford Algorithm Omar Saadi (College of Computing) Algorithmic Foundations 3 Computer Science School 2 / 13",
    "source": "Chapter8_AlgoFoundations_GA.pdf",
    "page": 2
  },
  {
    "text": "Introduction Outline 1 Introduction 2 Bellman-Ford Algorithm Omar Saadi (College of Computing) Algorithmic Foundations 3 Computer Science School 3 / 13",
    "source": "Chapter8_AlgoFoundations_GA.pdf",
    "page": 3
  },
  {
    "text": "Introduction Framework Definition A negative cycleon a graph (or digraph) is a cycle such that the sum of the weights of its edges is negative (i.e. < 0). We have a graph (or digraph) G = (V , E). Each edge ( u, v) ∈ E has a weight w(u, v) (that can be negative), but G has no negative cycles. We have a starting vertex s and a destination vertex d. We want to solve the shortest path problem : minimize P a s,d-path in G w(P), where w(P) is the weight of the path P given as the sum of the weights of the edges forming it. Omar Saadi (College of Computing) Algorithmic Foundations 3 Computer Science School 4 / 13",
    "source": "Chapter8_AlgoFoundations_GA.pdf",
    "page": 4
  },
  {
    "text": "Bellman-Ford Algorithm Outline 1 Introduction 2 Bellman-Ford Algorithm Omar Saadi (College of Computing) Algorithmic Foundations 3 Computer Science School 5 / 13",
    "source": "Chapter8_AlgoFoundations_GA.pdf",
    "page": 5
  },
  {
    "text": "Bellman-Ford Algorithm Bellman-Ford Algorithm Input :A graph (or digraph) with no negative cycles and a starting vertex s. Output :Distance d(s, u) from s to each other vertex u and a shortest path tree given by identifying the parent P(u) of each vertex u. Key idea :∀u ∈ V , the algorithm computes an estimate d[u] of the distance of u from the source s such that : At iteration k, d[u] is the length of a path from s to u. The estimate d[u] is non-increasing and it is updated in a dynamic programming way (a step by step way). At the last iteration n − 1, d[u] will contain d(s, u). Omar Saadi (College of Computing) Algorithmic Foundations 3 Computer Science School 6 / 13",
    "source": "Chapter8_AlgoFoundations_GA.pdf",
    "page": 6
  },
  {
    "text": "Bellman-Ford Algorithm Bellman-Ford Algorithm Initialization :Set d[s] = 0; P(s) = None. For u ̸= s, set d[u] = +∞ and P(u) = None. Iteration : for i from 1 to n − 1 do : for (u, v) ∈ E do : d[v] = min{d[v], d[u] + w(u, v)}, and if d[v] changes then P[v] = u. for (u, v) ∈ E do : if d[v] > d[u] + w(u, v) then return “A negative cycle exists” Return d[u] and P[u] for all u ∈ V . Remark :The order in which the edges are considered impacts the execution of the algorithm. A possible order of edges is to order the vertices and then take the outgoing edges of each one of them. Omar Saadi (College of Computing) Algorithmic Foundations 3 Computer Science School 7 / 13",
    "source": "Chapter8_AlgoFoundations_GA.pdf",
    "page": 7
  },
  {
    "text": "Bellman-Ford Algorithm Bellman-Ford detects negative cycles Proposition If there is a negative cycle reachable from the source s, then at the end we will have for some edge ( u, v) ∈ E, d(v) > d(u) + w(u, v). Proof Suppose v0 → v1 → ··· →vk is a negative cycle reachable from s, where v0 = vk , i.e. Pk i=1 w (vi−1, vi ) < 0. By absurd, suppose that at the end we have d(vi ) ≤ d(vi−1) + w(vi−1, vi ) for all i = 1, . . . ,k. Then taking the sum, we getPk i=1 d (vi ) ≤ Pk i=1 d (vi−1) + Pk i=1 w (vi−1, vi ). Observing that the first two terms are the same (because v0 = vk ), we deduce that : kX i=1 w (vi−1, vi ) ≥ 0. (which is absurd) Omar Saadi (College of Computing) Algorithmic Foundations 3 Computer Science School 8 / 13",
    "source": "Chapter8_AlgoFoundations_GA.pdf",
    "page": 8
  },
  {
    "text": "Bellman-Ford Algorithm To prove correctness of the distance estimates (at the end), we reformulate the algorithm in a dynamic programming way. This formulation is useful for the proof but not for space (and time) complexity : Bellman-Ford Algorithm (Variant 1) Initialization :For all k ∈ {0, ··· , n − 1}, set dk [s] = 0; Pk (s) = None and for all u ̸= s, set dk [u] = +∞ and Pk (u) = None. Iteration : for k from 1 to n − 1 do : for (u, v) ∈ E do* : dk [v] = min{dk−1[v], dk−1[u] + w(u, v), dk [v]}, and if dk [v] changes to dk−1[v] then Pk [v] = Pk−1[v], and if dk [v] changes to dk−1[u] + w(u, v) then Pk [v] = u. for (u, v) ∈ E do : if dn−1[v] > dn−1[u] + w(u, v) then return “A negative cycle exists” Return dn−1[u] and Pn−1[u] for all u ∈ V . *Note that this variant 1 of the algorithm is slower (and takes more storage space). Indeed, to have the same iteration as the original version we need to take dk [v] = min{dk−1[v], dk−1[u] + w(u, v), dk [v], dk [u] + w(u, v)}. ⇒ Proving that this variant 1 is correct proves the original version is correct too. Omar Saadi (College of Computing) Algorithmic Foundations 3 Computer Science School 9 / 13",
    "source": "Chapter8_AlgoFoundations_GA.pdf",
    "page": 9
  },
  {
    "text": "Bellman-Ford Algorithm Proposition If the graph G has no negative cycles, then dn−1[v] = d(s, v) for all vertices v, and backtracking from v to s using the parent list Pn−1 yields a shortest path from s to v. Proof By induction on k, we will prove that dk [v] is the minimum weight of a path from s to v that uses ≤ k edges. This will show that dn−1[v] is the distance from s to v because there is no negative cycles in the graph (a shortest path contains at most n − 1 edges). Base case :If k = 0, then dk [v] = 0 for v = s, and + ∞ otherwise. So the claim is satisfied. Inductive step :Suppose that for all vertices u, dk−1[u] is the minimum weight of a path from s to u that uses ≤ k − 1 edges. If v ̸= s, let P be a shortest simple path from s to v with ≤ k edges, and let u be the node just before v on P. Let Q be the path from s to u. Then Q is a shortest path from s to u that uses at most k − 1 edges. By the inductive hypothesis, w(Q) = dk−1[u]. Omar Saadi (College of Computing) Algorithmic Foundations 3 Computer Science School 10 / 13",
    "source": "Chapter8_AlgoFoundations_GA.pdf",
    "page": 10
  },
  {
    "text": "Bellman-Ford Algorithm Proof (Cont.) In iteration k, we update dk [v] = min (dk−1[v], dk−1[u] + w(u, v)). We know that dk [v] ≤ dk−1[u] + w(u, v) = w(Q) + w(u, v) = w(P), i.e. dk [v] ≤ w(P). Furthermore, dk [v] is the length of a path from s to v with at most k edges, which must be at least as large as w(P). Therefore, dk [v] = w(P) is the minimum weight of a path from s to v that uses at most k edges. Note that the update of the parents Pk (y) insures that the parent list Pk contains the parents in the shortest paths using at most k edges. So that, Pn−1 contains the parents in the shortest paths from s to v for every v ∈ V . Omar Saadi (College of Computing) Algorithmic Foundations 3 Computer Science School 11 / 13",
    "source": "Chapter8_AlgoFoundations_GA.pdf",
    "page": 11
  },
  {
    "text": "Bellman-Ford Algorithm Complexity Time complexity :We have the n − 1 iterations and in each iteration we go through all the edges in our graph. For each edge ( u, v) ∈ E, we do O(1) operations. Therefore the time complexity of the algorithm is : O(|V ||E|). Space complexity :The algorithm (in its original version) uses only the two lists d and P. Therefore, the space complexity is O(|V |). Remark :If at a given iteration k no distance d[u] is changed, then the algorithm can be stopped and the distance and shortest paths are found. Omar Saadi (College of Computing) Algorithmic Foundations 3 Computer Science School 12 / 13",
    "source": "Chapter8_AlgoFoundations_GA.pdf",
    "page": 12
  },
  {
    "text": "Bellman-Ford Algorithm Example In the following digraph, find the distances from vertex A to all the other vertices and the list of parents providing the shortest paths. A B C D E F G H 2 4 −1 4 5 −3 1 2 2 3−2 2 −3 Omar Saadi (College of Computing) Algorithmic Foundations 3 Computer Science School 13 / 13",
    "source": "Chapter8_AlgoFoundations_GA.pdf",
    "page": 13
  },
  {
    "text": "Chapter 9 : Shortest Path Problem (Floyd-Warshall Algorithm) and Transitive Closure (Warshall’s Algorithm) Omar Saadi omar.saadi@um6p.ma UM6P - College of Computing 1st year of the engineering degree of UM6P-CS Academic year 2024-2025 Omar Saadi (College of Computing) Algorithmic Foundations (GA) Computer Science School 1 / 18",
    "source": "Chapter9_AlgoFoundations3_GA.pdf",
    "page": 1
  },
  {
    "text": "Outline 1 Introduction 2 Floyd-Warshall Algorithm 3 Transitive Closure Omar Saadi (College of Computing) Algorithmic Foundations (GA) Computer Science School 2 / 18",
    "source": "Chapter9_AlgoFoundations3_GA.pdf",
    "page": 2
  },
  {
    "text": "Introduction Outline 1 Introduction 2 Floyd-Warshall Algorithm 3 Transitive Closure Omar Saadi (College of Computing) Algorithmic Foundations (GA) Computer Science School 3 / 18",
    "source": "Chapter9_AlgoFoundations3_GA.pdf",
    "page": 3
  },
  {
    "text": "Introduction Framework We have a digraph (or graph) G = (V , E). Each edge ( u, v) ∈ E has a weight w(u, v) (that can be negative), but G has no negative cycles. All Pairs Shortest Path problem For each pair of vertices s, t, we want to solve the problem : minimize P a s,t-path in G w(P), where w(P) is the weight of the path P given as the sum of the weights of the edges forming it. Omar Saadi (College of Computing) Algorithmic Foundations (GA) Computer Science School 4 / 18",
    "source": "Chapter9_AlgoFoundations3_GA.pdf",
    "page": 4
  },
  {
    "text": "Floyd-Warshall Algorithm Outline 1 Introduction 2 Floyd-Warshall Algorithm 3 Transitive Closure Omar Saadi (College of Computing) Algorithmic Foundations (GA) Computer Science School 5 / 18",
    "source": "Chapter9_AlgoFoundations3_GA.pdf",
    "page": 5
  },
  {
    "text": "Floyd-Warshall Algorithm Floyd-Warshall Algorithm Input :A digraph (or graph) G = (V , E) with |V | = n vertices. Output :(If there is no negative cycles)Distance d(s, t) from each vertex s to each vertex t and a shortest path tree (from each starting vertex s) given by identifying the parent P(s, t) of each vertex t in the shortest path from s to t. Omar Saadi (College of Computing) Algorithmic Foundations (GA) Computer Science School 6 / 18",
    "source": "Chapter9_AlgoFoundations3_GA.pdf",
    "page": 6
  },
  {
    "text": "Floyd-Warshall Algorithm Floyd-Warshall Algorithm Key ideas : The vertices of the digraph are identified with the integers from 1 to n (i.e. V = {1, ··· , n}). If k is the biggest vertex appearing on an s, t-shortest path, then d(s, t) = d(s, k) + d(k, t) and moreover, the sub-paths from s to k and from k to t only use vertices up to k − 1 internally. For each k going from 1 to n, we consider the problem of computing dk (s, t) which is the smallest weight of an s, t-path that only uses vertices 1, ··· , k internally. Omar Saadi (College of Computing) Algorithmic Foundations (GA) Computer Science School 7 / 18",
    "source": "Chapter9_AlgoFoundations3_GA.pdf",
    "page": 7
  },
  {
    "text": "Floyd-Warshall Algorithm Floyd-Warshall Algorithm Floyd-Warshall Algorithm Initialization : ∀u ∈ V , ∀k ∈ {0, ··· , n}, dk (u, u) = 0, Pk (u, u) = None ∀u, v ∈ V , u ̸= v, ∀k ∈ {1, ··· , n}, dk (u, v) = +∞, Pk (u, v) = None ∀(u, v) ∈ E, d0(u, v) = w(u, v), P0(u, v) = u ∀(u, v) ̸∈ E, d0(u, v) = +∞, P0(u, v) = None Iterations : for k from 1 to n do : for (u, v) ∈ V × V do : if dk−1(u, k) + dk−1(k, v) < dk−1(u, v) then dk (u, v) = dk−1(u, k) + dk−1(k, v) and Pk (u, v) = Pk−1(k, v), else dk (u, v) = dk−1(u, v) and Pk (u, v) = Pk−1(u, v). Return dn(u, v) and Pn(u, v) for all ( u, v) ∈ V × V . Omar Saadi (College of Computing) Algorithmic Foundations (GA) Computer Science School 8 / 18",
    "source": "Chapter9_AlgoFoundations3_GA.pdf",
    "page": 8
  },
  {
    "text": "Floyd-Warshall Algorithm Correctness Proposition If the digraph G has no negative cycles, then dn(s, t) = d(s, t) for all couple of vertices ( s, t), and backtracking from t to s using the parent list Pn yields a shortest path from s to t. Proof We prove by induction over k ∈ {0, ··· , n}, that dk (s, t) is the minimal length of a path from s to t which is allowed to use internally only the vertices smaller of equal to k. Base case :For k = 0, we initialize each d0(u, v) as the edge weight w(u, v) if ( u, v) ∈ E, else we set it to + ∞, so that d0(u, v) is exactly the length of a shortest path from s to t that don’t use any other vertex internally. P0(u, v) is also properly initialized. Inductive step :Let k ∈ {1, ··· , n} and suppose that the property is true up to k − 1. Omar Saadi (College of Computing) Algorithmic Foundations (GA) Computer Science School 9 / 18",
    "source": "Chapter9_AlgoFoundations3_GA.pdf",
    "page": 9
  },
  {
    "text": "Floyd-Warshall Algorithm Proof (Cont.) Let P be a shortest path from u to v using 1, ··· , k as intermediate vertices. We can assume that P is a simple path (since there are no negative cycles). There are two cases : 1 P contains k : In this case, we know that neither the path from u to k nor the path from k to v contains any vertices that are greater than k − 1. Then, by the induction hypothesis we get dk−1(u, k) + dk−1(k, v) = w(P) ≤ dk−1(u, v). Therefore, in the algorithm, dk (u, v) = dk−1(u, k) + dk−1(k, v) = w(P) and Pk (u, v) = Pk−1(k, v) is the predecessor of v in a shortest path from u to v using only vertices between 1 and k internally. 2 P does not contain k : In this case P uses only vertices between 1 and k − 1, then w(P) = dk−1(u, v) ≤ dk−1(u, k) + dk−1(k, v). Therefore, from the algorithm, dk (u, v) = dk−1(u, v) = w(P) and Pk (u, v) = Pk−1(u, v) is an adequate update of the predecessor of v. Omar Saadi (College of Computing) Algorithmic Foundations (GA) Computer Science School 10 / 18",
    "source": "Chapter9_AlgoFoundations3_GA.pdf",
    "page": 10
  },
  {
    "text": "Floyd-Warshall Algorithm Detection of negative cycles Proposition The digraph contains a negative cycle if and only if Floyd-Warshall algorithm returns dn such that dn(u, u) < 0 for some vertex u. Proof If there is a cycle C from u to u of negative weight, then dn(u, u) will be at most the weight of this cycle C, and hence, will be negative. Otherwise, and since d0(u, u) = 0 in the beginning of the algorithm, no update can cause dn(u, u) to become negative. Omar Saadi (College of Computing) Algorithmic Foundations (GA) Computer Science School 11 / 18",
    "source": "Chapter9_AlgoFoundations3_GA.pdf",
    "page": 11
  },
  {
    "text": "Floyd-Warshall Algorithm Complexity Time Complexity :The runtime of the Floyd-Warshall algorithm is proportional to the size of the table {dk (u, v)}(k,u,v)∈V 3 (which is the same size of the table of predecessors {Pk (u, v)}(k,u,v)∈V 3 ). Indeed, filling each entry of the table d (and also of P) only depends on at most two other entries filled in before it. Therefore, the time complexity is : O \u0000 |V |3\u0001 . Space Complexity :Note that we can choose to store only the table of the current iteration ( dk (u, v), ∀(u, v) ∈ V 2) and the one of the previous iteration (dk−1(u, v), ∀(u, v) ∈ V 2) instead of storing all the tables dk , ∀k ∈ {0, ··· , n}. Therefore, the space complexity is : O \u0000 |V |2\u0001 . Omar Saadi (College of Computing) Algorithmic Foundations (GA) Computer Science School 12 / 18",
    "source": "Chapter9_AlgoFoundations3_GA.pdf",
    "page": 12
  },
  {
    "text": "Floyd-Warshall Algorithm Example In the following digraph, use Floyd-Warshall algorithm to find the distances between all pairs of vertices and the list of parents providing the shortest paths rooted at each vertex. A B CD 3 5 4 −2 1 3 2 −1 Omar Saadi (College of Computing) Algorithmic Foundations (GA) Computer Science School 13 / 18",
    "source": "Chapter9_AlgoFoundations3_GA.pdf",
    "page": 13
  },
  {
    "text": "Transitive Closure Outline 1 Introduction 2 Floyd-Warshall Algorithm 3 Transitive Closure Omar Saadi (College of Computing) Algorithmic Foundations (GA) Computer Science School 14 / 18",
    "source": "Chapter9_AlgoFoundations3_GA.pdf",
    "page": 14
  },
  {
    "text": "Transitive Closure Transitive Closure of a digraph Definition 1 Given a digraph G = (V , E), we call the transitive closureof G, the subset T of V × V such that for all ( u, v) ∈ V × V , (u, v) ∈ T if and only if there is a path from u to v in G. Definition 2 A digraph G is transitive if it satisfies : for all vertices u, v, w, if (u, v) ∈ E and (v, w) ∈ E then (u, w) ∈ E. Lemma The transitive closure T of a graph G gives the smallest set of edges that needs to be added to make the graph G transitive. Proof Remark that if a path from u to v exists in G then necessarily the edge (u, v) needs to be added to G to make it transitive and that adding all such edges suffices to make the digraph transitive. Omar Saadi (College of Computing) Algorithmic Foundations (GA) Computer Science School 15 / 18",
    "source": "Chapter9_AlgoFoundations3_GA.pdf",
    "page": 15
  },
  {
    "text": "Transitive Closure Warshall’s Algorithm Input :A digraph G = (V , E) with |V | = n vertices. Output :The set T of couples ( u, v) ∈ V × V , such that there exists a path from u to v in the graph G. Key ideas :Similar procedure as Floyd-Warshall algorithm. The vertices of the digraph are identified with the integers from 1 to n (i.e. V = {1, ··· , n}). If (u, v) ∈ T and k is the biggest vertex appearing on an u, v-path, then (u, k) ∈ T and (k, v) ∈ T and moreover, the sub-paths from u to k and from k to v only use vertices up to k − 1 internally. For each k going from 1 to n, we consider the problem of identifying if there is a u,v-path that only uses vertices 1 , ··· , k internally. If such path exists we put ck (u, v) = 1, otherwise we put ck (u, v) = 0. Omar Saadi (College of Computing) Algorithmic Foundations (GA) Computer Science School 16 / 18",
    "source": "Chapter9_AlgoFoundations3_GA.pdf",
    "page": 16
  },
  {
    "text": "Transitive Closure Warshall’s Algorithm Initialization : ∀u, v ∈ V , ∀k ∈ {1, ··· , n}, ck (u, v) = 0 ∀(u, v) ∈ E, c0(u, v) = 1 ∀(u, v) ̸∈ E, c0(u, v) = 0 Iterations : for k from 1 to n do : for (u, v) ∈ V × V do* : if ck−1(u, v) = 1 or ( ck−1(u, k) = 1 and ck−1(k, v) = 1) then ck (u, v) = 1, Return cn(u, v) for all ( u, v) ∈ V × V . * : This is similar to writing the following (with boolean variables) : ck (u, v) = ck−1(u, v) or \u0002 ck−1(u, k) and ck−1(k, v) \u0003 . Omar Saadi (College of Computing) Algorithmic Foundations (GA) Computer Science School 17 / 18",
    "source": "Chapter9_AlgoFoundations3_GA.pdf",
    "page": 17
  },
  {
    "text": "Transitive Closure Correctness and complexity of Warshall’s algorithm Proposition For all ( u, v) ∈ V × V , we have cn(u, v) = 1 if and only if there exists a path from u to v in the digraph G, i.e. T = {(u, v) ∈ V 2 | cn(u, v) = 1}. Proof : Similar to the proof for Floyd-Warshall algorithm. Similar to Floyd-Warshall algorithm, we have the following complexities for Warshall’s algorithm : Time Complexity :O(|V |3). Space Complexity :O(|V |2). Omar Saadi (College of Computing) Algorithmic Foundations (GA) Computer Science School 18 / 18",
    "source": "Chapter9_AlgoFoundations3_GA.pdf",
    "page": 18
  },
  {
    "text": "Theory of computation 1 Lecture 1: Automata and Regular languages Adnane Saoud Monday, September 2, 2024",
    "source": "Lecture 1.pdf",
    "page": 1
  },
  {
    "text": "• Engineering degree (École Mohammadia d’ingénieurs) • Ph.D. in Control theory and Computer science at CentraleSupélec and ENS Paris-Saclay, France (2019) • Postdoc researcher at UC Santa Cruz, USA (2020) • Postdoc researcher at UC Berkeley, USA (2021) • Professor at CentraleSupélec (Sep 2021 – Aug 2022) • Professor at UM6P-CC (Since Sept 2023) Research interests: Control theory, machine learning, computer science About Me 2",
    "source": "Lecture 1.pdf",
    "page": 2
  },
  {
    "text": "The Team 3 Instructor: Adnane Saoud Office: SHBM, College of Computing offices Office hours: I will be available Wednesday and Thursday (between 16:00 and 18:00) Or, send me an email and we will find a good time to meet Email: adnane.saoud@um6p.ma TA: Emmanuel Junior WAFO WEMBE (Ph.D. student, Control of monotone dynamical systems) Email: EmmanuelJunior.WafoWembe@um6p.ma TA: Sadek Belamfedel Alaoui (Postdoctoral researcher, Reinforcement learning -based control) Email: sadek.belamfedel@um6p.ma",
    "source": "Lecture 1.pdf",
    "page": 3
  },
  {
    "text": "4 What is computation theory ?",
    "source": "Lecture 1.pdf",
    "page": 4
  },
  {
    "text": "Introduction 5 Computability Theory - What is computable or not (problems that are solvable or not) - Examples: program verification, mathematical truth - Models of Computation: Finite automata: used in text processing, compilers, control of systems context- free grammar: used in programming languages and artificial intelligence Complexity Theory - What is computable in practice? - What makes some problems computationally easy or hard - Example: sorting and factoring problems - P versus NP problem",
    "source": "Lecture 1.pdf",
    "page": 5
  },
  {
    "text": "6 About this course",
    "source": "Lecture 1.pdf",
    "page": 6
  },
  {
    "text": "The main learning objectives of the course are as follows: • Formal Languages: Learn about formal languages, their syntax, and semantics. Describe and recognize different types of formal languages such as regular languages and context-free languages. • Automata Theory: Learn the fundamentals of automata theory such as finite automata, pushdown automata, and T uring machines. Learn how to design these machines, analyze their behavior, and understand their computational power. • Computability Theory: Learn the concept of computability, the Church-T uring thesis, and the Halting problem. Explore the limits of what is computationally solvable and understand undecidability. • Complexity Theory: Learn about computational complexity tools such as time and space complexity classes like P , NP . Be able to distinguish between problems that can be solved efficiently and those that are NP-complete or harder. • Problem Solving and Proof T echniques: Develop problem-solving skills by learning how to construct proofs. Be able to prove whether a problem is decidable or undecidable. • Practical Applications: While the primary focus is on theory, the course provides insights into practical applications, demonstrating how theoretical concepts relate to real-world computational problems. • Preparation for Advanced Studies: The course serves as a foundational course to pursue more advanced studies in computer science, in areas related to formal methods, automata theory. Learning Objectives 7",
    "source": "Lecture 1.pdf",
    "page": 7
  },
  {
    "text": "Five components: 1. Lectures ▪ Thursday’s (and sometimes also Monday) 2. T utorials ▪ Monday (First session) Guided exercises sessions with the instructor 3. Labs ▪ Thursdays (Second session) Hands-on experience on computation theory tools Labs will not be graded, but will help you to further understand the material presented in the lectures Final Labs will be graded 4. Recitations ▪ Thursdays (Second session) Open exercises sessions for discussions and for answering questions 5. Project ▪ Thursdays (Second session) Structure of the Course 8",
    "source": "Lecture 1.pdf",
    "page": 8
  },
  {
    "text": "Course Logistics • Canvas for Q&A and material – You will receive an email shortly providing a link the Canvas – All announcements will be posted there – Also, lecture slides, tutorials and labs – Please, participate and help each other! 9",
    "source": "Lecture 1.pdf",
    "page": 9
  },
  {
    "text": "Reading Material 10 • The book is publicly available in electronic form – Pointers to chapters for every lecture (see the canvas)",
    "source": "Lecture 1.pdf",
    "page": 10
  },
  {
    "text": "• Please ask questions, participate in discussions on Canvas • Play with software tools. Apply what you’ve learnt in theory – This is the actual goal of the lab sessions and the recitations • Give us your feedback! Some Personal Notes ☺ 11",
    "source": "Lecture 1.pdf",
    "page": 11
  },
  {
    "text": "12 Topics that will be covered",
    "source": "Lecture 1.pdf",
    "page": 12
  },
  {
    "text": "1. Introduction, Finite Automata, Regular Expressions 2. Nondeterminism, Closure Properties, from Regular Expressions to finite automata 3. The Regular Pumping Lemma, from Finite Automata to Regular Expressions, Context free grammar 4. Pushdown Automata, equivalence between pushdown automata and context free grammar 5. The Context free Pumping Lemma, Turing Machines 6. Turing machine Variants, the Church-Turing Thesis … Idea about the Schedule (Subject to Change) 13",
    "source": "Lecture 1.pdf",
    "page": 13
  },
  {
    "text": "14 Finite automata",
    "source": "Lecture 1.pdf",
    "page": 14
  },
  {
    "text": "Finite Automata 15 Input: finite string Output: Accept or Reject Computation process: Begin at start state, read input symbols, follow corresponding transitions, Accept if end with accept state, Reject if not. Examples: 01101 → Accept 00101 → Reject 𝑀1 accepts exactly those strings in 𝐴 where 𝐴 = {𝑤| 𝑤 contains substring 11}. 𝑀1 𝑞1 𝑞2 𝑞3 1 0,1 0 10 States: 𝑞1 𝑞2 𝑞3 Transitions: Start state: Accept states: 1 𝐴 is the language of 𝑀1 and that 𝑀1 recognizes 𝐴 and that 𝐴 = 𝐿(𝑀1).",
    "source": "Lecture 1.pdf",
    "page": 15
  },
  {
    "text": "Finite Automata – Formal Definition 16 Definition: A finite automaton 𝑀 is a 5-tuple (𝑄, Σ, 𝛿, 𝑞0, 𝐹) • 𝑄 finite set of states • Σ finite set of alphabet symbols • 𝛿 transition function 𝛿: 𝑄 × Σ → 𝑄 • 𝑞0 start state • 𝐹 set of accept states 𝛿 (𝑞, 𝑎) = 𝑟 means 𝑞 𝑟a 𝑀1 𝑞1 𝑞2 𝑞3 1 0,1 0 10 𝑀1 = (𝑄, Σ, 𝛿, 𝑞1, 𝐹) 𝑄 = {𝑞1, 𝑞2, 𝑞3} Σ = {0, 1} 𝐹 = {𝑞3} 0 1 𝑞1 𝑞1 𝑞2 𝑞2 𝑞1 𝑞3 𝑞3 𝑞3 𝑞3 𝛿 = Example:",
    "source": "Lecture 1.pdf",
    "page": 16
  },
  {
    "text": "17 Regular languages",
    "source": "Lecture 1.pdf",
    "page": 17
  },
  {
    "text": "Definition: A language is regular if some finite automaton recognizes it. Finite Automata and Regular languages 18 Strings and languages - A string is a finite sequence of symbols in Σ - A language is a set of strings - The empty string ε is the string of length 0 - The empty language ø is the set with no strings Definition: 𝑀 accepts string 𝑤 = 𝑤1𝑤2 … 𝑤𝑛 each 𝑤𝑖 𝜖 Σ if there is a sequence of states 𝑟0, 𝑟1, 𝑟2, , … , 𝑟𝑛 𝜖 𝑄 where: - 𝑟0 = 𝑞0 - 𝑟𝑖 = 𝛿(𝑟𝑖−1, 𝑤𝑖) for 1 ≤ 𝑖 ≤ 𝑛 - 𝑟𝑛 𝜖 𝐹Recognizing languages - 𝐿(𝑀) = {𝑤| 𝑀 accepts 𝑤} - 𝐿(𝑀) is the language of 𝑀 - 𝑀 recognizes 𝐿(𝑀)",
    "source": "Lecture 1.pdf",
    "page": 18
  },
  {
    "text": "Regular Languages – Examples 𝐿 𝑀1 = {𝑤| 𝑤 contains substring 11} = 𝐴 Therefore 𝐴 is regular 𝑀1 𝑞1 𝑞2 𝑞3 1 0,1 0 10 Example of a non regular language: Let 𝐶 = 𝑤 𝑤 has equal numbers of 0s and 1s} 𝐶 is not regular (will be proven in next lectures). 19",
    "source": "Lecture 1.pdf",
    "page": 19
  },
  {
    "text": "Regular Expressions Regular operations. Let 𝐴, 𝐵 be languages: - Union: 𝐴 ∪ 𝐵 = 𝑤 𝑤 ∈ 𝐴 or 𝑤 ∈ 𝐵} - Concatenation: 𝐴 ∘ 𝐵 = 𝑥𝑦 𝑥 ∈ 𝐴 and 𝑦 ∈ 𝐵} = 𝐴𝐵 - Star: 𝐴∗ = 𝑥1 … 𝑥𝑘 each 𝑥𝑖 ∈ 𝐴 for 𝑘 ≥ 0} Note: ε ∈ 𝐴∗ always Example. Let 𝐴 = {ab,bc} and 𝐵 = {fg, hk}. - 𝐴 ∪ 𝐵 - 𝐴 ∘ 𝐵 = 𝐴𝐵 - 𝐴∗ 20",
    "source": "Lecture 1.pdf",
    "page": 20
  },
  {
    "text": "Regular Expressions Goal: Show that finite automata are equivalent to regular expressions Regular expressions - Built from Σ, members Σ, ∅, ε [Atomic] - By using ∪,∘,∗ [Composite] Examples: - 0 ∪ 1 ∗ = Σ∗ gives all strings over Σ - Σ∗1 gives all strings that end with 1 - Σ∗11Σ∗ = all strings that contain 11 = 𝐿 𝑀1 21",
    "source": "Lecture 1.pdf",
    "page": 21
  },
  {
    "text": "22 Closure properties",
    "source": "Lecture 1.pdf",
    "page": 22
  },
  {
    "text": "Closure Properties for Regular Languages Theorem: If 𝐴1, 𝐴2 are regular languages, so is 𝐴1 ∪ 𝐴2 (closure under ∪) Proof: Let 𝑀1 = (𝑄1, Σ, 𝛿1 , 𝑞1 , 𝐹1 ) recognize 𝐴1 𝑀2 = (𝑄2, Σ, 𝛿2 , 𝑞2 , 𝐹2 ) recognize 𝐴2 Construct 𝑀 = (𝑄 , Σ, 𝛿 , 𝑞0, 𝐹 ) recognizing 𝐴1 ∪ 𝐴2 𝑀 should accept input 𝑤 if either 𝑀1 or 𝑀2 accept 𝑤. 𝑀2 𝑟 𝑀1 𝑞 ? 𝑀 23",
    "source": "Lecture 1.pdf",
    "page": 23
  },
  {
    "text": "Closure Properties for Regular Languages Theorem: If 𝐴1, 𝐴2 are regular languages, so is 𝐴1 ∪ 𝐴2 (closure under ∪) Proof: Let 𝑀1 = (𝑄1, Σ, 𝛿1 , 𝑞01 , 𝐹1 ) recognize 𝐴1 𝑀2 = (𝑄2, Σ, 𝛿2 , 𝑞02 , 𝐹2 ) recognize 𝐴2 Construct 𝑀 = (𝑄 , Σ, 𝛿 , 𝑞0, 𝐹 ) recognizing 𝐴1 ∪ 𝐴2 𝑀 should accept input 𝑤 if either 𝑀1 or 𝑀2 accept 𝑤. Components of 𝑴: 𝑄 = 𝑄1 × 𝑄2 = 𝑞1, 𝑞2 𝑞1 ∈ 𝑄1 and 𝑞2 ∈ 𝑄2} 𝑞0 = (𝑞01, 𝑞02) 𝛿 𝑞, 𝑟 , 𝑎 = 𝛿1 𝑞, 𝑎 , 𝛿2 𝑟, 𝑎 𝐹 = 𝐹1 × 𝐹2 𝐹 = 𝐹1 × 𝑄2 ∪ 𝑄1 × 𝐹2 when we need this? Theorem: If 𝐴1, 𝐴2 are regular languages, so is 𝐴1 ∩ 𝐴2 24",
    "source": "Lecture 1.pdf",
    "page": 24
  },
  {
    "text": "25 Summary",
    "source": "Lecture 1.pdf",
    "page": 25
  },
  {
    "text": "Summary 26 1. Introduction, outline of the course 2. Finite Automata and regular languages: formal definition 3. Regular Operations and Regular Expressions 4. Theorem: Class of regular languages is closed under union and intersection",
    "source": "Lecture 1.pdf",
    "page": 26
  },
  {
    "text": "Theory of computation 1 Lecture 3: Automata and Regular languages Adnane Saoud Thursday, September 19, 2024",
    "source": "Lecture 3.pdf",
    "page": 1
  },
  {
    "text": "Summary of lecture 2 Lecture 2 ▪ Nondeterministic finite automatas (NFAs) ▪ Closure under ∘ and ∗ ▪ How to convert regular expressions to finite automata Lecture 3 ▪ From finite automata to regular expressions ▪ Proving some languages are not regular ▪ Context free grammars 2",
    "source": "Lecture 3.pdf",
    "page": 2
  },
  {
    "text": "3 From finite automata to regular expressions",
    "source": "Lecture 3.pdf",
    "page": 3
  },
  {
    "text": "DFAs → Regular Expressions Recall Theorem: If a language is described by a regular expression then it is regular Proof: Conversion 𝑅 → NFA 𝑀 → DFA 𝑀′ Today’s Theorem: If a language 𝐴 is regular then it can described as regular expression Proof: Give conversion DFA 𝑀 → 𝑅 We need a new concept: GNFA. • From DFA to GNFA • From GNFA to Regular expressions Regular expression 𝑅 𝑀 Finite automaton 4",
    "source": "Lecture 3.pdf",
    "page": 4
  },
  {
    "text": "Generalized NFAs Definition: A Generalized Nondeterministic Finite Automaton (GNFA) is similar to an NFA, but allows regular expressions as transition labels 5 We first convert the GNFA to have this special form: • The start state has transition arrows going to every other state but no arrows coming in from any other state. • There is only a single accept state, and it has arrows coming in from every other state but no arrows going to any other state. Furthermore, the accept state is not the same as the start state. • Except for the start and accept states, one arrow goes from every state to every other state and also from each state to itself. 𝐺1 𝑞1 aba∗b∗ b a 𝑞3 a ∪ b aab 𝑞2",
    "source": "Lecture 3.pdf",
    "page": 5
  },
  {
    "text": "Generalized NFAs Definition: A Generalized Nondeterministic Finite Automaton (GNFA) is similar to an NFA, but allows regular expressions as transition labels 6 How to convert the GNFA into the special form: • The start state has transition arrows going to every other state but no arrows coming in from any other state. ➢ Add a new start state with an ε arrow to the old start state • There is only a single accept state, and it has arrows coming in from every other state but no arrows going to any other state. Furthermore, the accept state is not the same as the start state. ➢ Add a new accept state with ε arrows from the old accept states. • Except for the start and accept states, one arrow goes from every state to every other state and also from each state to itself. ➢ If there are multiple arrows going between the same two states in the same direction, we replace each with a single arrow whose label is the union of the previous labels. ➢ We add arrows labeled ∅ between states that had no arrows",
    "source": "Lecture 3.pdf",
    "page": 6
  },
  {
    "text": "7 GNFA → Regular Expressions Lemma: Every GNFA 𝐺 has an equivalent regular expression 𝑅 Proof: By induction on the number of states 𝑘 of 𝐺 Basis (𝑘 = 2): Let 𝑅 = 𝑟 Induction step (𝑘 > 2): Assume Lemma true for 𝑘 − 1 states and prove for 𝑘 states IDEA: Convert 𝑘-state GNFA to equivalent 𝑘 − 1 -state GNFA 𝑟𝐺 = 𝐺 is in special form 𝑘 states GNFA 𝑘 − 1 states GNFA",
    "source": "Lecture 3.pdf",
    "page": 7
  },
  {
    "text": "𝑘-state GNFA → (𝑘—1)-state GNFA 𝑘 − 1 states𝑘 states 𝑥 𝑥 𝑞𝑖 𝑞𝑗𝑞𝑖 𝑞𝑗 𝑟1 𝑟2 𝑟3 𝑟4 𝑟1 𝑟2 ∗𝑟3 ∪ 𝑟4 1. Pick any state 𝑥 except the start and accept states. 2. Remove 𝑥. 3. Repair the damage by recovering all paths that went through 𝑥. 4. Make the indicated change for each pair of states 𝑞𝑖, 𝑞𝑗. 8",
    "source": "Lecture 3.pdf",
    "page": 8
  },
  {
    "text": "9 Pumping Lemma",
    "source": "Lecture 3.pdf",
    "page": 9
  },
  {
    "text": "Non-Regular Languages 10 How do we show a language is not regular? - To show a language is regular, we give a DFA. - To show a language is not regular, we must give a proof. - It is not enough to say that you couldn’t find a DFA for it, therefore the language isn’t regular .",
    "source": "Lecture 3.pdf",
    "page": 10
  },
  {
    "text": "Method for Proving Non-regularity 11 Pumping Lemma: For every regular language 𝐴, there is a number 𝑝 (the “pumping length”) such that for any string 𝑠 ∈ 𝐴 satisfying 𝑠 ≥ 𝑝 there exist 𝑥, 𝑦 and 𝑧 such that 𝑠 = 𝑥𝑦𝑧 where 1) 𝑥𝑦𝑖𝑧 ∈ 𝐴 for all 𝑖 ≥ 0 𝑦𝑖 = 𝑦𝑦 ⋯ 𝑦 2) 𝑦 ≠ ε 3) 𝑥𝑦 ≤ 𝑝 Informally: 𝐴 is regular → every long string in 𝐴 can be pumped and the result stays in 𝐴. Proof: Let DFA 𝑀 recognize 𝐴. Let 𝑝 be the number of states in 𝑀. Pick 𝑠 ∈ 𝐴 where 𝑠 ≥ 𝑝. 𝑖 𝑥 𝑦 𝑧 𝑀 𝑞𝑗 𝑠 = 𝑥 𝑦 𝑧 𝑞𝑗 𝑞𝑗 𝑀 will repeat a state 𝑞𝑗 when reading 𝑠 because 𝑠 is so long. The path that 𝑀 follows when reading 𝑠. 𝑥 𝑦 𝑦 𝑧 𝑞𝑗 𝑞𝑗 𝑞𝑗 is also accepted",
    "source": "Lecture 3.pdf",
    "page": 11
  },
  {
    "text": "Example 1 of Proving Non-regularity 12 Let 𝐷 = 0𝑘1𝑘 𝑘 ≥ 0} Show: 𝐷 is not regular Proof by Contradiction: Assume (to get a contradiction) that 𝐷 is regular . The pumping lemma gives 𝑝 as above. Let 𝑠 = 0𝑝1𝑝 ∈ 𝐷. Pumping lemma says that can divide 𝑠 = 𝑥𝑦𝑧 satisfying the 3 conditions. But 𝑥𝑦𝑦𝑧 has excess 0s and thus 𝑥𝑦𝑦𝑧 ∉ 𝐷 contradicting the pumping lemma. Therefore our assumption (𝐷 is regular) is false. We conclude that 𝐷 is not regular. Pumping Lemma: For every regular language 𝐴, there is a 𝑝 such that for any string 𝑠 ∈ 𝐴 satisfying 𝑠 ≥ 𝑝 there exist 𝑥, 𝑦 and 𝑧 such that 𝑠 = 𝑥𝑦𝑧 where 1) 𝑥𝑦𝑖𝑧 ∈ 𝐴 for all 𝑖 ≥ 0 𝑦𝑖 = 𝑦𝑦 ⋯ 𝑦 2) 𝑦 ≠ ε 3) 𝑥𝑦 ≤ 𝑝 ≤ 𝑝 𝑧𝑥 𝑦 𝑠 = 000 ⋯ 000111 ⋯ 111",
    "source": "Lecture 3.pdf",
    "page": 12
  },
  {
    "text": "Example 2 of Proving Non-regularity 13 Let 𝐹 = 𝑤𝑤 𝑤 ∈ Σ∗} . Say Σ∗ = {0,1}. Show: 𝐹 is not regular Proof by Contradiction: Assume (for contradiction) that 𝐹 is regular . The pumping lemma gives 𝑝 as above. Need to choose 𝑠 ∈ 𝐹. Which 𝑠? Try 𝑠 = 0𝑝0𝑝 ∈ 𝐹. But that 𝑠 can be pumped and stay inside 𝐹. Bad choice. Try 𝑠 = 0𝑝10𝑝1 ∈ 𝐹. Show cannot be pumped 𝑠 = 𝑥𝑦𝑧 satisfying the 3 conditions. 𝑥𝑦𝑦𝑧 ∉ 𝐹 Contradiction! Therefore 𝐹 is not regular. 𝑠 = 000 ⋯ 001000 ⋯ 001 ≤ 𝑝 𝑧𝑥 𝑦",
    "source": "Lecture 3.pdf",
    "page": 13
  },
  {
    "text": "Example 3 of Proving Non-regularity 14 Let 𝐵 = 𝑤 𝑤 has equal numbers of 0s and 1s} Show: 𝐵 is not regular Proof by Contradiction: Assume (for contradiction) that 𝐵 is regular . We know that 0∗1∗ is regular so 𝐵 ∩ 0∗1∗ is regular (closure under intersection). But 𝐷 = 𝐵 ∩ 0∗1∗ and we already showed 𝐷 is not regular. Contradiction! Therefore our assumption is false, so 𝐵 is not regular. Variant: Combine closure properties with the Pumping Lemma.",
    "source": "Lecture 3.pdf",
    "page": 14
  },
  {
    "text": "Converting NFAs to DFAs 15 Theorem: If an NFA recognizes 𝐴 then 𝐴 is regular Proof: Let NFA 𝑀 = (𝑄, Σ, 𝛿, 𝑞0 , 𝐹) recognize 𝐴 Construct DFA 𝑀′ = (𝑄′, Σ, 𝛿′, 𝑞0 ′ , 𝐹′) recognizing 𝐴 (Ignore the ε-transitions, can easily modify to handle them) IDEA: DFA 𝑀′ keeps track of the subset of possible states in NFA 𝑀. ε- transitions, can easily modify to handle them) Construction of 𝑴′: 𝑄′ = 𝓟 𝑄 𝛿′ 𝑅, 𝑎 = 𝑞 𝑞 ∈ 𝛿(𝑟, 𝑎) for some 𝑟 ∈ 𝑅} 𝑞0 ′ = {q0} 𝐹′ = 𝑅 ∈ 𝑄′ 𝑅 intersects 𝐹} 6 Context-free Languages",
    "source": "Lecture 3.pdf",
    "page": 15
  },
  {
    "text": "Context Free Grammars 16 } ((Substitution) Rules Rule: Variable → string of variables and terminals Variables: Symbols appearing on left-hand side of rule Terminals: Symbols appearing only on right-hand side Start Variable: Top left symbol Grammars generate strings 1. Write down start variable 2. Replace any variable according to a rule Repeat until only terminals remain 3. Result is the generated string 4. 𝐿(𝐺) is the language of all generated strings. 3 rules R,S 0,1 S S → 0S1 S → R R → ε 𝐺1 In 𝐺1:",
    "source": "Lecture 3.pdf",
    "page": 16
  },
  {
    "text": "Context Free Grammars 17 } ((Substitution) Rules S → 0S1 S → R R → ε 𝐺1 Example of 𝐺1 generating a string S 0 S 1 0 S 1 R ε S 0S1 00S11 00R11 0011 𝐿 𝐺1 = 0𝑘1𝑘 𝑘 ≥ 0} Tree of substitutions Resulting string ∈ 𝐿 𝐺1",
    "source": "Lecture 3.pdf",
    "page": 17
  },
  {
    "text": "18 Summary",
    "source": "Lecture 3.pdf",
    "page": 18
  },
  {
    "text": "Summary 19 1. DFAs, NFAs, regular expressions are all equivalent 2. Proving languages not regular by using the pumping lemma and closure properties 3. Context Free Grammars",
    "source": "Lecture 3.pdf",
    "page": 19
  },
  {
    "text": "Analyse numériqueSéance 4: Résolution de systèmes d’équations linéaires. Partie 2Mohammed-Khalil Ferradikhalil.ferradi@um6p.ma1",
    "source": "chapitre_4.pdf",
    "page": 1
  },
  {
    "text": "2 Méthodes de résolution directes:- Méthode d’élimination de Gauss: le principe de la méthode est de transformer le système initial à résoudre 𝑨𝒙=𝒃en un système équivalent 𝑴𝑨𝒙=𝑴𝒃, tel que la matrice 𝑴𝑨est triangulaire supérieure et sans calculer explicitement la matrice 𝑴.Cette méthode est associée à la factorisation LUde la matrice: 𝑨=𝑳𝑼, avec LetU des matrices triangulaires inférieure et supérieure respectivement. Une fois la factorisation LU obtenue, on résout le système 𝑳𝒚=𝒃, puis le système 𝑼𝒙=𝒚. Pour obtenir 𝒙.-Méthode de Cholesky: cette méthode est valable pour une matrice 𝑨symétrique définie positive. Elle se base sur une factorisation de la matrice sous la forme suivante: 𝑨=𝑳்𝑳. On résout alors le système 𝑳்𝒚=𝒃, puis pour obtenir 𝒙le système 𝑳𝒙=𝒚.",
    "source": "chapitre_4.pdf",
    "page": 2
  },
  {
    "text": "3 - Le principe de la méthode de Gauss est de transformer le système à résoudre en une forme triangulaire.- La méthode est basée sur des combinaisons linéaires des lignes de la matrice. Par exemple pour un vecteur de dimension 2 : 𝒂்=𝑎ଵ𝑎ଶ, si 𝑎ଵ≠ 0, alors:De manière plus générale:Avec 𝑚௜=௔೔௔ೖ ,𝑖=𝑘+1,…,𝑛et 𝑎௞≠0est appelé pivot.1 0−𝑎ଶ𝑎ଵ1𝑎ଵ𝑎ଶ=𝑎ଵ0𝑴௞𝒂=1 … 0 0 … 0⋮ ⋱ ⋮ ⋮ ⋱ ⋮0 … 1 0 … 00 … −𝑚௞ାଵ 1 … 0⋮ ⋱ ⋮ ⋮ ⋱ ⋮0 … −𝑚௡0 … 1𝑎ଵ⋮𝑎௞𝑎௞ାଵ⋮𝑎௡=𝑎ଵ⋮𝑎௞0⋮0 Méthode de Gauss:",
    "source": "chapitre_4.pdf",
    "page": 3
  },
  {
    "text": "4 - La matrice 𝑴௞est appelée matrice d’élimination élémentaire. Elle rajoute des multiples de la ligne kaux lignes qui suivent, de manière à avoir des termes nuls au-dessous du terme en k.-La matrice 𝑴௞est triangulaire inférieure et inversible. Elle peut être représentée sous la forme suivante:Et 𝒆௞le kièmevecteur colonne de la matrice identité.- L’inverse de la matrice 𝑴௞noté 𝑳௞=𝑴௞ିଵest égale à:𝑴௞=𝑰−𝒎௞𝒆௞் , avec 𝒎௞=0 … 0𝑚௞ାଵ…𝑚௡்𝑳௞=𝑰+𝒎௞𝒆௞்",
    "source": "chapitre_4.pdf",
    "page": 4
  },
  {
    "text": "5 - Pour deux matrices d’éliminations élémentaires 𝑴௞et 𝑴௝, avec j > k, leur produit est égal à:Pareil pour 𝑳௞𝑳௝: 𝑳௞𝑳௝=𝑰+𝒎௞𝒆௞்+𝒎௝𝒆௝்Exemple:Pour 𝒂=24−2: 𝑴ଵ𝒂=1−2 11 0 124−2=200, 𝑴ଶ𝒂=10 10 1/2 124−2=240𝑴௞𝑴௝=𝑰−𝒎௞𝒆௞்𝑰−𝒎௝𝒆௝்=𝑰−𝒎௞𝒆௞்−𝒎௝𝒆௝்+𝒎௞𝒆௞்𝒎௝𝒆௝்𝑴௞𝑴௝=𝑰−𝒎௞𝒆௞்−𝒎௝𝒆௝்𝑴ଵ𝑴ଶ=1−2 11 1/2 1",
    "source": "chapitre_4.pdf",
    "page": 5
  },
  {
    "text": "6 - Pour la réduction d’un système d’équations linéaires 𝑨𝒙=𝒃sous forme triangulaire supérieure, on choisit d’abord 𝑎ଵଵ≠ 0comme pivot avec la matrice d’élimination 𝑴ଵcorrespondante, pour mettre à zéro les termes sous la diagonale de la 1èrecolonne :- Ensuite, avec le nouveau pivot 𝑎ଶଶ≠ 0de la matrice 𝑴ଵ𝑨, la matrice d’élimination 𝑴ଶcorrespondante est utilisée pourmettre à zéro les termes sous la diagonale de la 2ièmecolonne :- le processus est répété jusqu’à ce que le système soit complètement écrit sous forme triangulaire supérieure:Le système ainsi obtenu peut être résolu par substitution rétrograde (back-substitution). Ce processus est appelé méthode de Gauss. 𝑴ଵ𝑨𝒙=𝑴ଵ𝒃𝑴ଶ𝑴ଵ𝑨𝒙=𝑴ଶ𝑴ଵ𝒃𝑴௡ିଵ…𝑴ଶ𝑴ଵ𝑨𝒙=𝑴௡ିଵ…𝑴ଶ𝑴ଵ𝒃⇒ 𝑴𝑨𝒙=𝑴𝒃",
    "source": "chapitre_4.pdf",
    "page": 6
  },
  {
    "text": "7 Système initial à résoudre:𝑨𝒙=𝑎ଵଵ଴𝑎ଵଶ଴𝑎ଵଷ଴…𝑎ଵ௡଴𝑎ଶଵ଴𝑎ଶଶ଴𝑎ଶଷ଴…𝑎ଶ௡଴𝑎ଷଵ଴𝑎ଷଶ଴𝑎ଷଷ଴…𝑎ଷ௡଴⋮ ⋮ ⋮ ⋱ ⋮𝑎௡ଵ଴𝑎௡ଶ଴𝑎௡ଷ଴…𝑎௡௡଴𝑥ଵ𝑥ଶ𝑥ଷ⋮𝑥௡=𝑏ଵ଴𝑏ଶ଴𝑏ଷ଴⋮𝑏௡଴𝑎ଵଵ଴𝑎ଵଶ଴𝑎ଵଷ଴…𝑎ଵ௡଴0𝑎ଶଶଵ𝑎ଶଷଵ…𝑎ଶ௡ଵ0𝑎ଷଶଵ𝑎ଷଷଵ…𝑎ଷ௡ଵ⋮ ⋮ ⋮ ⋱ ⋮0𝑎௡ଶଵ𝑎௡ଷଵ…𝑎௡௡ଵ ,𝑏ଵଵ𝑏ଶଵ𝑏ଷଵ⋮𝑏௡ଵ1ièreélimination:𝑎ଵଵ଴𝑎ଵଶ଴𝑎ଵଷ଴…𝑎ଵ௡଴0𝑎ଶଶଵ𝑎ଶଷଵ…𝑎ଶ௡ଵ0 0𝑎ଷଷଶ…𝑎ଷ௡ଶ⋮ ⋮ ⋮ ⋱ ⋮0 0𝑎௡ଷଶ…𝑎௡௡ଶ ,𝑏ଵଶ𝑏ଶଶ𝑏ଷଶ⋮𝑏௡ଶ2ièmeélimination:(n-1)ièmeélimination:𝑎ଵଵ଴𝑎ଵଶ଴𝑎ଵଷ଴…𝑎ଵ௡଴0𝑎ଶଶଵ𝑎ଶଷଵ…𝑎ଶ௡ଵ0 0𝑎ଷଷଶ…𝑎ଷ௡ଶ⋮ ⋮ ⋮ ⋱ ⋮0 0 0 …𝑎௡௡௡ିଵ ,𝑏ଵ௡ିଵ𝑏ଶ௡ିଵ𝑏ଷ௡ିଵ⋮𝑏௡௡ିଵQue faire si lors de la ièmeélimination le pivot est nul ?",
    "source": "chapitre_4.pdf",
    "page": 7
  },
  {
    "text": "8 - L’inverse de la matrice 𝑴:Est une matrice triangulaire inférieure.- Le résultat 𝑼=𝑴𝑨est par construction une matrice triangulaire supérieure. On a donc:- Si au cours de la méthode de Gauss un des termes diagonaux est nul, la matrice 𝑼sera singulière. Néanmoins la factorisation LU est toujours possible.- La méthode de Gauss produit une factorisation LUd’une matrice donnée. La méthode de Gauss et la factorisation LUsont donc un même processus pour résoudre un système d’équations linéaires.- Une fois la factorisation LUde la matrice est obtenue, il devient facile d’obtenir le vecteur solution:𝑳=𝑴ିଵ=𝑴ଵିଵ…𝑴௡ିଵିଵ=𝑳ଵ…𝑳௡ି𝟏𝑨=𝑳𝑼on résout 𝑳𝒚=𝒃, puis 𝑼𝒙=𝒚",
    "source": "chapitre_4.pdf",
    "page": 8
  },
  {
    "text": "9 Exemple:𝑆: 1 2 53 2 −10 5 3𝒙=10,51𝑆ଵ: 1 0 0−3 1 00 0 1𝑴భ 1 2 53 2 −10 5 3𝒙=10,51 ⇒ 1 2 50 −4 −160 5 3𝒙=1−2,51𝑆ଶ: 1 0 00 1 00 1,25 1𝑴మ 1 2 50 −4 −160 5 3𝒙=1−2,51 ⇒ 1 2 50 −4 −160 0 −17𝒙=1−2,5−2,125𝑼𝒙ୀ𝑴𝒃Résolution du système 𝑆ଶpar substitution : 𝑥ଵ=𝑥ଶ=𝑥ଷ=ଵ଼",
    "source": "chapitre_4.pdf",
    "page": 9
  },
  {
    "text": "10 Pour obtenir explicitement la factorisation LU, on calcule la matrice L:On obtient donc la factorisation LU de la matrice A:𝑳=𝑴ଶ𝑴ଵିଵ=𝑳ଵ𝑳ଶ𝑳=1 0 03 1 00 0 11 0 00 1 00 −1,25 1=1 0 03 1 00 −1,25 1𝑨=1 2 53 2 −10 5 3=1 0 03 1 00 −1,25 11 2 50 −4 −160 0 −17=𝑳𝑼",
    "source": "chapitre_4.pdf",
    "page": 10
  },
  {
    "text": "11 Technique du pivot partiel (partial pivoting):- T oute valeur non nulle peut être utilisée comme pivot. Néanmoins en pratique le pivot peut être choisi de telle manière à minimiser les erreurs de calculs.- Pour ne pas amplifier les erreurs d’arrondis lors de la multiplication du reste de la matrice à triangulariser avec la matrice d’élimination élémentaire, la valeur absolue des termes de la matrice élémentaire ne doit pas dépasser 1.- Ceci est obtenu en choisissant comme pivot d’une étape de la méthode de Gauss, la plus grande valeur possible entre la valeur du terme de la diagonale et les valeurs en dessous dans la même colonne.- Cette procédure, appelée pivot partiel, est essentiel pour une implémentation numérique stable de la méthode de Gauss.",
    "source": "chapitre_4.pdf",
    "page": 11
  },
  {
    "text": "12 - Avec le pivot partiel, à chaque étape kde la méthode de Gauss, on effectue une permutation 𝑷௞avant de multiplier par la matrice 𝑴௞, de manière à toujours avoir le plus grand pivot possible dans la diagonale. On obtient toujours 𝑴𝑨=𝑼 avec 𝑼 une matrice triangulaire supérieure, mais avec 𝑴égale à:-La matrice 𝑳=𝑴ିଵn’est pas nécessairement triangulaire inférieure (triangulaire à npermutations près).-On peut effectuer les permutations en amont de la méthode de Gauss pour obtenir:Avec 𝑷=𝑷௡ିଵ…𝑷ଶ𝑷ଵreprésente les permutations effectuées sur les lignes de la matrice 𝑨, et 𝑳étant maintenant triangulaire inférieure.𝑴=𝑴௡ିଵ𝑷௡ିଵ…𝑴ଶ𝑷ଶ𝑴ଵ𝑷ଵ𝑷𝑨=𝑳𝑼",
    "source": "chapitre_4.pdf",
    "page": 12
  },
  {
    "text": "13 - La technique du pivot partiel peut être généralisé à celle du pivot total, en considérant cette fois ci comme pivot le plus grand terme du reste de la matrice à triangulariser .- Le pivot total requiert une permutation des colonnes en plus de celle des lignes de la matrice. La factorisation s’exprime donc sous la forme suivante:Avec 𝑷et𝑸les matrices permutations, et 𝑳et 𝑼étant les matrices triangulaires inférieure et supérieure de la factorisation.- La stabilité numérique du pivot total et plus grande que celle du pivot partiel, mais la recherche du pivot devient plus coûteuse en temps de calcul.𝑷𝑨𝑸=𝑳𝑼",
    "source": "chapitre_4.pdf",
    "page": 13
  },
  {
    "text": "14 Exemple:On considère la matrice à factoriser suivante : avec 0 <𝜀<𝜀௠௔௖௛Si les lignes ne sont pas permutées, le pivot est égal à 𝜀:Avec une arithmétique en virgule flottante, la matrice 𝑼devient: 𝑼=𝜀10 −1/𝜀et donc:𝑨=𝜀11 1𝑴𝑨=1 0−1𝜀1𝜀11 1=𝜀10 1 − 1/𝜀=𝑼 , 𝑳=1 01/𝜀1𝑳𝑼=1 01/𝜀1𝜀10 −1/𝜀=𝜀11 0≠𝑨- L’utilisation d’un pivot ayant une faible valeur a eu pour conséquence une perte en précision du procédé de factorisation",
    "source": "chapitre_4.pdf",
    "page": 14
  },
  {
    "text": "15 On utilise maintenant la méthode du pivot partiel. Le pivot est donc égal à 1 et on obtient:𝑴𝑷𝑨=1 0−𝜀11 1𝜀1=1 10 1 −𝜀=𝑼 , 𝑳=1 0𝜀1Avec une arithmétique en virgule flottante, la matrice 𝑼devient: 𝑼=1 10 1et donc:𝑳𝑼=1 0𝜀11 10 1=1 1𝜀1 +𝜀≈1 1𝜀1=𝑷𝑨",
    "source": "chapitre_4.pdf",
    "page": 15
  },
  {
    "text": "16 Pour certains types de matrices couramment utilisées, il n’est pas nécessaire d’effectuer un changement de pivot:-Matrice à diagonale strictement dominante:-Matrice symétrique définie positive: (les valeurs propres de la matrice sont toutes strictement positives)෍𝑎௜௝< |𝑎௜௜|௡௜ୀଵ,௜ஷ௝ , 𝑗= 1, … ,𝑛𝑨=𝑨் , 𝒙்𝑨𝒙> 0 pour tout 𝒙≠𝟎Une matrice définie positive est nécessairement à diagonale dominante, l’inverse n’étant pas forcément vérifié.",
    "source": "chapitre_4.pdf",
    "page": 16
  },
  {
    "text": "17 Exemple:En utilisant une précision à trois chiffres, on résout le système suivant:La méthode de Gauss avec pivot partiel mène au système triangulaire suivant:Qu’on résout par substitution rétrograde:Malgré un résidu faible correspondant à la précision à 3 chiffres utilisée, la solution approchée 𝒙ෝest loin de la solution exacte 𝒙்=1 1. Ceci est dû au conditionnement de la matrice (𝜅𝑨> 8000) 0,641 0,2420,321 0,121𝑥ଵ𝑥ଶ=0,8830,4420,641 0,2420 0,000242𝑥ଵ𝑥ଶ=0,883−0,000383⇒ 𝒙ෝ=0,7821,58 , 𝒓=𝒃−𝑨𝒙ෝ=−0,000622−0,000202",
    "source": "chapitre_4.pdf",
    "page": 17
  },
  {
    "text": "18 Remarques générales sur la factorisation LU:- Si deux factorisations de la même matrice sont disponibles: 𝑨=𝑳𝑼=𝑳෠𝑼෡, alors 𝑳෠ିଵ𝑳=𝑼෡𝑼ିଵ=𝑫, avec 𝑫une matrice diagonale. - Si 𝑳et 𝑳෠sont des matrices triangulaires inférieures unitaires (termes diagonaux égaux à 1), alors 𝑫=𝑰, et donc 𝑳=𝑳෠et 𝑼=𝑼෡. - Pour une factorisation 𝑨=𝑳𝑼avec 𝑳une matrice triangulaire inférieure unitaire, alors cette factorisation est unique.- La procédure de factorisation requiert environ 𝑛ଷ/3opérations de multiplication et un nombre similaire d’additions. Auxquelles il faut rajouter environ 2𝑛ଶopérations pour la résolution du système par substitution.- Le calcul direct de l’inverse 𝑨ିଵrequiert environ 𝑛ଷopérations. Pour le calcul de l’inverse, on résout 𝑛systèmes linéaires en plus de la factorisation, ce qui est donc plus coûteux que la résolution d’un seul système après la factorisation.",
    "source": "chapitre_4.pdf",
    "page": 18
  },
  {
    "text": "19 Méthode (factorisation) de Cholesky:- Si 𝑨est une matrice symétrique définie positive, alors la factorisation LUpeut être remplacée par la factorisation de Cholesky𝑼=𝑳்: Avec 𝑳une matrice triangulaire inférieure avec des termes diagonaux positifs.Exemple:𝑨=𝑳𝑳்𝑎ଵଵ𝑎ଶଵ𝑎ଶଵ𝑎ଶଶ=𝑙ଵଵ0𝑙ଶଵ𝑙ଶଶ𝑙ଵଵ𝑙ଶଵ0𝑙ଶଶ ⇒ 𝑙ଵଵ=𝑎ଵଵ , 𝑙ଶଵ=𝑎ଶଵ𝑙ଵଵ , 𝑙ଶଶ=𝑎ଶଶ−𝑙ଶଵଶ",
    "source": "chapitre_4.pdf",
    "page": 19
  },
  {
    "text": "20 Algorithme de factorisation de Cholesky pour une matrice 𝑨=𝑎௜௝ଵஸ௜,௝ஸ௡:Pour k = 1 , n𝑙௞௞=𝑎௞௞pour j = k+1 , n𝑙௝௞=𝑎௝௞/𝑙௞௞pour i = k+1 , j𝑎௜௝=𝑎௜௝−𝑙௜௞𝑙௝௞retourner𝑳=𝑙௜௝ଵஸ௜,௝ஸ௡- La factorisation de Cholesky requiert 𝑛ଷ/6opérations de multiplication, ce qui est deux fois moins que la factorisation LU.- Elle ne requiert aucun changement de pivot au cours de la procédure.",
    "source": "chapitre_4.pdf",
    "page": 20
  },
  {
    "text": "21 Raffinement itératif des résultats:On suppose qu’on a une première approximation 𝒙଴de la solution du système 𝑨𝒙=𝒃. Le résidu est égal à:Pour améliorer la solution, on résout 𝑨𝒛଴=𝒓଴et on incrémente la solution:𝒙ଵest une meilleure solution, puisque:Le processus peut être répété jusqu’à l’obtention d’un résultat à la machine précision près.𝒓଴=𝒃−𝑨𝒙଴𝒙ଵ=𝒙଴+𝒛଴𝑨𝒙ଵ=𝑨𝒙଴+𝒛଴=𝑨𝒙଴+𝑨𝒛଴𝑨𝒙ଵ=𝒃−𝒓଴+𝒓଴=𝒃",
    "source": "chapitre_4.pdf",
    "page": 21
  },
  {
    "text": "22 - Le raffinement itératif nécessite de stocker la matrice et sa factorisation en même temps.- Puisque la factorisation LU de la matrice 𝑨est déjà connue, le processus de raffinement du résultat nécessite seulement la résolution d’un système triangulaire par substitution.- Pour pallier les erreurs d’annulation, le résidu doit généralement être calculé avec une précision élevée pour produire des résultats pertinents.",
    "source": "chapitre_4.pdf",
    "page": 22
  },
  {
    "text": "23Fin de la séance",
    "source": "chapitre_4.pdf",
    "page": 23
  },
  {
    "text": "Analyse numériqueSéance 1: Introduction et résolution d’équations non-linéairesMohammed-Khalil Ferradikhalil.ferradi@um6p.ma1",
    "source": "chapitre_1.pdf",
    "page": 1
  },
  {
    "text": "2 Qu’est-ce que l’analyse numérique ?L’analyse numérique est une branche des mathématiques appliquées, ayant pour objectif l’étude des algorithmes permettant d’approximer les solutions de problèmes mathématiques.But:- Simulation de phénomènes physiques réels- Conception sur un modèle virtuelDomaines d’applications: - Calcul des structures: ponts, barrages, tunnels…- Mécanique des fluides: Modélisation du flux d’air chaud pour le séchage du phosphate- Optimisation- … Introduction:",
    "source": "chapitre_1.pdf",
    "page": 2
  },
  {
    "text": "3 Exemple 1:Approximation de Pi par la méthode d’Archimède: Pour n=96, Archimède a obtenu l’approximation suivante:3 +1071≤𝜋≤ 3 +17Utilisation d’une approche par l’intérieur et par l’extérieur pour obtenir un encadrement du résultat (et donc de l’erreur).",
    "source": "chapitre_1.pdf",
    "page": 3
  },
  {
    "text": "4 Simulation de la rupture d’un câble de précontrainte tendu à 350t Exemple 2: Simulation de la rupture d’un câble",
    "source": "chapitre_1.pdf",
    "page": 4
  },
  {
    "text": "5 - Au milieu de XXième siècle et avant l’avènement de l’ère informatique, les calculs étaient faits par des « humancomputers ». À la NASA, la résolution des équations pour le calcul de la trajectoire d’un engin spatial était faite par des algorithmes calculés manuellement.- Le développement de l’analyse numérique est intimement lié à celui des machines de calcul: résolution de problèmes à plusieurs millions de variables avec un simple ordinateur personnel.- Le but du modélisateur utilisant les méthodes d’analyse numérique est d’approximer la solution des équations mathématiques régissant un problème réel, tout en réduisant l’erreur numérique, le temps de calcul, et l’utilisation de la mémoire machine.",
    "source": "chapitre_1.pdf",
    "page": 5
  },
  {
    "text": "6 Résolution d’équations non-linéaires:Pour une fonction notée 𝑓𝑥, on cherche la valeur 𝑥∗solution de l’équation suivante: 𝑓𝑥= 0- La solution 𝑥∗est appelée racine ou zéro de la fonction f.- Plusieurs solutions peuvent exister .On peut deux distinguer deux cas:•Les fonctions à une dimension 𝑓: ℝ → ℝayant une solution scalaire. •Un système couplé à ndimensions, avec 𝒇: ℝ௡→ ℝ௡, dont la solution au système 𝒇𝒙=𝟎est un vecteur .",
    "source": "chapitre_1.pdf",
    "page": 6
  },
  {
    "text": "7 - Exemple d’équation non-linéaire à une dimension:- Exemple d’un système d’équations non-linéaires :tan𝑥−𝑥= 0Dont des solutions approximées sont: 7.72, 14.07, …𝑥ଵଶ−𝑥ଶ+ 0,25 = 0−𝑥ଵ+𝑥ଶଶ+ 0,25 = 0Dont la solution est le vecteur 𝒙்=0.5 0.5",
    "source": "chapitre_1.pdf",
    "page": 7
  },
  {
    "text": "8 - L’existence est l’unicité d’une solution est plus difficile à déterminer pour les équations non-linéaires que pour les équations linéaires.- Pour une fonction continue 𝑓:𝑎,𝑏→ ℝ, si signe𝑓𝑎≠ signe𝑓𝑏, alors le TVI implique ∃𝑥∗ tel que 𝑓𝑥∗= 0.- Il n’y a pas d’analogue à ce résultat en dimension 𝑛> 1.- Les équations non-linéaires peuvent avoir un nombre quelconque de solutions, voire pas de solution.𝑒௫+ 1 = 0 nᇱa pas de solution𝑥ଶ− 1 = 0 a deux solutionstan𝑥−𝑥=0 a une infinité de solutions",
    "source": "chapitre_1.pdf",
    "page": 8
  },
  {
    "text": "9 Méthode de dichotomie (ou de bissection):La méthode de dichotomie requiert un intervalle initial 𝑎,𝑏vérifiant signe𝑓𝑎≠ signe𝑓𝑏, dont la longueur est divisée par deux à chaque itération, jusqu’à l’obtention de la convergence avec la précision souhaitée.L’algorithme s’exprime comme suit:Choisir une précision 𝜀> 0et un intervalle initial 𝑎,𝑏vérifiant signe𝑓𝑎≠ signe𝑓𝑏T ant que 𝑏−𝑎>𝜀faire:𝑐=௔ା௕ଶsi signe𝑓𝑎= signe𝑓𝑐alorsa = csinonb = c",
    "source": "chapitre_1.pdf",
    "page": 9
  },
  {
    "text": "10 Exemple:Intervalle de recherche initial 1,3.𝑓𝑥=𝑥ଶ− 4 sin(𝑥) = 0",
    "source": "chapitre_1.pdf",
    "page": 10
  },
  {
    "text": "11 - La méthode de la bissection n'utilise pas les valeurs des fonctions ni leurs dérivées, seulement leurs signes. - La méthode est certaine de converger, mais très lentement (la convergence est linéaire).- Pour un intervalle de départ donné [a, b], la longueur de l'intervalle après k itérations est (b - a)/2k, donc pour atteindre une tolérance d'erreur 𝜀, il faut environ quel que soit la fonctionf impliquée.logଶ𝑏−𝑎𝜀 itérations",
    "source": "chapitre_1.pdf",
    "page": 11
  },
  {
    "text": "12 Méthode du point fixe:- On appelle 𝑥un point fixe d’une fonction 𝑔: ℝ → ℝs’il vérifie:- De nombreuses méthodes itératives pour résoudre des équations non-linéaires utilisent un schéma d'itération à point fixe ayant la forme suivante:où les points fixes de gsont des solutions de l'équation 𝑓𝑥= 0.Exemple: le point fixe de la fonction 𝑔𝑥= tan𝑥est une solution de l’équation 𝑓𝑥= tan𝑥−𝑥= 0.- Pour une équation donnée 𝑓𝑥= 0, on peut avoir plusieurs représentations équivalentes sous la forme d’un problème de recherche de point fixe 𝑥=𝑔𝑥, avec différents choix pour la fonction g.𝑥=𝑔𝑥𝑥௞ାଵ=𝑔𝑥௞",
    "source": "chapitre_1.pdf",
    "page": 12
  },
  {
    "text": "13 - T oute fonction 𝑔𝑥 n’admet pas forcément un point fixe.- Si la suite 𝑥௞définie par une valeur initiale 𝑥଴et les itérations 𝑥௞ାଵ=𝑔𝑥௞converge, alors elle converge nécessairement vers un point fixe.- Un schéma d’itération à point fixe ne converge pas forcément, même si la fonction admet un point fixe.- Si 𝑥∗=𝑔𝑥∗et 𝑔ᇱ𝑥∗< 1, alors il existe un intervalle contenant 𝑥∗tel que les itérations 𝑥௞ାଵ=𝑔𝑥௞convergent vers 𝑥∗.",
    "source": "chapitre_1.pdf",
    "page": 13
  },
  {
    "text": "14 Pour la fonction 𝑓𝑥=𝑥ଶ−𝑥− 2, les points fixes des fonctions suivantes:représentent des solutions de l’équation 𝑓𝑥= 0.𝑔𝑥=𝑥ଶ− 2𝑔𝑥=𝑥+ 2𝑔𝑥= 1 +2𝑥𝑔𝑥=𝑥ଶ+ 22𝑥− 1",
    "source": "chapitre_1.pdf",
    "page": 14
  },
  {
    "text": "15",
    "source": "chapitre_1.pdf",
    "page": 15
  },
  {
    "text": "16",
    "source": "chapitre_1.pdf",
    "page": 16
  },
  {
    "text": "17",
    "source": "chapitre_1.pdf",
    "page": 17
  },
  {
    "text": "18 Méthode de Newton:On souhaite calculer la solution de l’équation suivante:𝑓𝑥= 0À partir d’un point initial 𝑥଴, l’équation à résoudre est linéarisée en utilisant l’approximation (linéarisation) suivante:ℒ𝑓𝑥= 0 ⇒ 𝑓𝑥଴+𝑓ᇱ𝑥଴Δ𝑥= 0Δ𝑥= −𝑓𝑥଴𝑓ᇱ𝑥଴ ⇒ 𝑥ଵ=𝑥଴+ Δ𝑥Calcul de l’incrément Δ𝑥:Vérification du critère de convergence: 𝑓𝑥ଵ<𝜀avec 𝜀> 0la précision souhaitéeLe calcul est répété jusqu’à l’atteinte de la convergence avec la précision fixée",
    "source": "chapitre_1.pdf",
    "page": 18
  },
  {
    "text": "19 L’algorithme de résolution de l’équation 𝑓𝑥= 0par la méthode de Newton est:Choisir un 𝑥଴initial et une précision 𝜀> 0T ant que 𝑓𝑥௜> εfaire:𝑥௜ାଵ=𝑥௜−௙௫೔௙ᇲ௫೔𝑖←𝑖+ 1Peut-on utiliser un critère de convergence (d’arrêt) autre que 𝑓𝑥௜<𝜀?",
    "source": "chapitre_1.pdf",
    "page": 19
  },
  {
    "text": "20 Représentation graphique de la méthode de Newton:𝑥଴𝑥ଵ𝑥ଷ𝑥ଶ𝑥∗𝑓𝑥଴𝑓𝑥ଵ𝑓𝑥ଶ𝑓𝑥ଷ 𝑥𝑓𝑥𝑥∗vérifiant 𝑓𝑥∗= 0𝑦",
    "source": "chapitre_1.pdf",
    "page": 20
  },
  {
    "text": "21 Exemple: calcul de la racine carrée de 2𝑓𝑥=𝑥ଶ− 2 = 0𝑥଴=𝟏𝑥ଵ=𝑥଴−𝑓𝑥଴𝑓ᇱ𝑥଴= 1 +12=𝟏, 5𝑥ଶ=𝟏,𝟒𝟏6666667𝑥ଷ=1,414215686274509803921568627451𝑥ସ=1.41421356237468991062629557889013491011655𝑥ହ=1.41421356237309504880168962350253024361498(24 chiffres exacts)(12 chiffres exacts)(6 chiffres exacts)",
    "source": "chapitre_1.pdf",
    "page": 21
  },
  {
    "text": "22 Définition de l’ordre de convergence:Soit une suite 𝑥௞convergeant vers sa limite 𝑥∗: lim௞→ାஶ𝑥௞=𝑥∗On dit que la suite converge en un ordre 𝛼s’il existe 𝐶> 0tel que:𝑥௞ାଵ−𝑥∗𝑥௞−𝑥∗ఈ≤𝐶 , 𝑘≥ 0la suite 𝑥௞converge:- linéairement s’il existe 0 <𝜏< 1tel que : 𝑥௞ାଵ−𝑥∗≤𝜏𝑥௞−𝑥∗pour ksuffisamment grand- Super-linéairement si : lim௫→ାஶ௫ೖశభି௫∗௫ೖି௫∗= 0- Quadratiquement s’il existe 𝐶> 0tel que: 𝑥௞ାଵ−𝑥∗≤𝐶𝑥௞−𝑥∗ଶpour ksuffisamment grand- Cubiquement s’il existe 𝐶>0tel que: 𝑥௞ାଵ−𝑥∗≤𝐶𝑥௞−𝑥∗ଷpour ksuffisamment grand",
    "source": "chapitre_1.pdf",
    "page": 22
  },
  {
    "text": "23 Preuve de la convergence quadratique de la méthode de Newton:On considère l’équation suivante 𝑓𝑥= 0, avec fau moins deux fois dérivable, et 𝑥∗vérifiant 𝑓𝑥∗= 0,𝑓ᇱ𝑥∗≠ 0.On écrit le développement de T aylor de fau voisinage de la solution 𝑥∗: 𝑓𝑥∗=𝑓𝑥௡+𝑓ᇱ𝑥௡𝑥∗−𝑥௡+𝑓ᇱᇱ𝜉௡2!𝑥∗−𝑥௡ଶAvec 𝜉௡compris entre 𝑥∗et 𝑥௡𝑥∗=𝑥௡−𝑓𝑥௡𝑓ᇱ𝑥௡௫೙శభ−𝑓ᇱᇱ𝜉௡2𝑓ᇱ𝑥௡𝑥∗−𝑥௡ଶ ⟹ 𝑥∗−𝑥௡ାଵ= −𝑓ᇱᇱ𝜉௡2𝑓ᇱ𝑥௡𝑥∗−𝑥௡ଶ𝑒௡ାଵ=𝑓ᇱᇱ𝜉௡2𝑓ᇱ𝑥௡𝑒௡ଶ ⟹ 𝑒௡ାଵ<𝐶𝑒௡ଶAvec 0 <𝐶= sup௫∈ூ௙ᇲᇲ௫ଶ௙ᇲ௫< +∞On démontre donc la convergence quadratique de la méthode",
    "source": "chapitre_1.pdf",
    "page": 23
  },
  {
    "text": "24 - Le choix du point de départ 𝑥଴a une influence sur la convergence de la méthode de Newton. En effet, 𝑥଴doit être choisi suffisamment proche de la solution pour que l’algorithme puisse converger .Exemple: 𝑓𝑥= tanିଵ𝑥= 0𝑥௞ାଵ=𝑥௞−1 +𝑥௞ଶtanିଵ𝑥௞ 𝑥ସ= 7,963 × 10ିଵ଴𝑥ଷ= −1,061 × 10ିଷ𝑥ଶ= 0,1169𝑥ଵ= −0,5707𝑥଴= 1𝑥ସ= 1,22 × 10ହ𝑥ଷ= −279,3𝑥ଶ= 13,95𝑥ଵ= −3,536𝑥଴= 2- Si la solution 𝑥∗vérifie 𝑓ᇱ𝑥∗= 0, la convergence n’est plus quadratique est devient donc lente.Exemple:𝑓𝑥=𝑥ଶ= 0𝑥௞ାଵ=𝑥௞−𝑥௞ଶ2𝑥௞=𝑥௞2(convergence linéaire)",
    "source": "chapitre_1.pdf",
    "page": 24
  },
  {
    "text": "25 Méthode de la sécante:- La méthode de Newton nécessite de calculer la dérivée de la fonction fà chaque itération, ce qui peut s’avérer coûteux en temps de calcul ou difficile à obtenir pour certaines fonctions.- La méthode de la sécante propose d’utiliser une approximation de la dérivée au lieu de la dérivée elle-même. Le calcul du nouveau point à une itération donnée s’exprime donc par:𝑥௜ାଵ=𝑥௜−𝑓𝑥௜𝑥௜−𝑥௜ିଵ𝑓𝑥௜−𝑓𝑥௜ିଵ",
    "source": "chapitre_1.pdf",
    "page": 25
  },
  {
    "text": "26𝑥଴𝑥ଵ𝑥ଶ𝑥∗𝑓𝑥଴𝑓𝑥ଵ𝑓𝑥ଶ 𝑥𝑓𝑥𝑦Représentation graphique de la méthode de la sécante: Le principe de la méthode de la sécante remonte à l’Egypte antique. Dans le papyrus de Berlin, la méthode est utilisée pour trouver les aires de deux carrés différents dont la somme est égale à 100 (coudées au carré), et dont le rapport des côtés de ces deux carrés étant de 1 pour (1/2 + 1/4). 𝑥ଷ",
    "source": "chapitre_1.pdf",
    "page": 26
  },
  {
    "text": "27Fin de la séance",
    "source": "chapitre_1.pdf",
    "page": 27
  }
]